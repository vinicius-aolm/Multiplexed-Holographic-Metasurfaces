{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsq9NG0E6h+xsVXjjlwmYQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Arquitetura\n","\n","Uma CPPN treinada com uma GAN e associada a um NSGA-II:\n","- CPPN: Gera padrões, controlado por parâmetros (pesos, ativações, topologia);\n","- NSGA-II: Algoritmo evolutivo multiobjetivo, evolui os parâmetros da CPPN;\n","- GAN: Adversarial training, fornece feedback “perceptual” à CPPN, o discriminador julga se os padrões são realistas;\n","\n","# Ideia de Aplicação\n","\n","Este script gera \"arte\" usando um algoritmo genético (NSGA-II) para \"evoluir\" redes neurais especiais chamadas CPPNs. Primeiro, ele baixa o enorme dataset WikiArt para treinar um \"crítico de arte\" (um Discriminador). Uma vez que o crítico aprende a diferenciar arte real de falsa, o algoritmo NSGA-II evolui uma população de CPPNs por 20 gerações, recompensando aquelas que criam imagens (64x64) que o crítico considera \"realistas\" e que ao mesmo tempo são visualmente \"diversificadas\". Ao final, o script salva as 10 melhores imagens abstratas resultantes desse processo evolutivo na pasta out_evolved.\n","\n","\n","\n","# Importações de Bibliotecas"],"metadata":{"id":"fQBxGUUD4KSY"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"exU9RYwAaUXS","executionInfo":{"status":"ok","timestamp":1762011997351,"user_tz":180,"elapsed":5656,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}},"outputId":"e7d110c6-b819-4d92-e034-57bc30d35d8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: pymoo in /usr/local/lib/python3.12/dist-packages (0.6.1.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.16.3)\n","Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.8.0)\n","Requirement already satisfied: cma>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from pymoo) (4.4.0)\n","Requirement already satisfied: alive-progress in /usr/local/lib/python3.12/dist-packages (from pymoo) (3.3.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from pymoo) (0.3.8)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: about-time==4.2.1 in /usr/local/lib/python3.12/dist-packages (from alive-progress->pymoo) (4.2.1)\n","Requirement already satisfied: graphemeu==0.7.2 in /usr/local/lib/python3.12/dist-packages (from alive-progress->pymoo) (0.7.2)\n","Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->pymoo) (2.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"]}],"source":["!pip install torch torchvision numpy matplotlib pillow pymoo"]},{"cell_type":"code","source":["!pip install pymoo #Biblioteca pymoo para utilizar o GA multiobjetivo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blH9JTNlGnAv","executionInfo":{"status":"ok","timestamp":1762012081065,"user_tz":180,"elapsed":5509,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}},"outputId":"f484b552-051c-481f-8467-b3e2cc03cb29"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pymoo in /usr/local/lib/python3.12/dist-packages (0.6.1.5)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from pymoo) (2.0.2)\n","Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.16.3)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.12/dist-packages (from pymoo) (3.10.0)\n","Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.8.0)\n","Requirement already satisfied: cma>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from pymoo) (4.4.0)\n","Requirement already satisfied: alive-progress in /usr/local/lib/python3.12/dist-packages (from pymoo) (3.3.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from pymoo) (0.3.8)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.3.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n","Requirement already satisfied: about-time==4.2.1 in /usr/local/lib/python3.12/dist-packages (from alive-progress->pymoo) (4.2.1)\n","Requirement already satisfied: graphemeu==0.7.2 in /usr/local/lib/python3.12/dist-packages (from alive-progress->pymoo) (0.7.2)\n","Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->pymoo) (2.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n"]}]},{"cell_type":"code","source":["import math\n","import os\n","import copy\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from pymoo.core.problem import Problem\n","from pymoo.optimize import minimize\n","from pymoo.algorithms.moo.nsga2 import NSGA2\n","from pymoo.termination import get_termination\n","\n","from datasets import load_dataset\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset"],"metadata":{"id":"0dODv0EnOsqG","executionInfo":{"status":"ok","timestamp":1762030974638,"user_tz":180,"elapsed":29,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Importação do Dataset\n","\n","Composto por 81.444 peças de arte divido em 129 artírtas, 11 gêneros e 27 classes de estilo;\n","\n","Link: https://huggingface.co/datasets/huggan/wikiart?utm_source=chatgpt.com"],"metadata":{"id":"CfaFVtwsNVWW"}},{"cell_type":"code","source":["# from datasets import load_dataset\n","\n","# ds = load_dataset(\"huggan/wikiart\")"],"metadata":{"id":"7eaTnnh3GghC","executionInfo":{"status":"ok","timestamp":1762033350958,"user_tz":180,"elapsed":12,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Funções e Classes\n","\n","## Adaptação do dataset bruto:\n","Esta classe adapta o dataset bruto para o PyTorch, garantindo que cada imagem seja RGB e aplicando as transformações necessárias, como redimensionamento e normalização, antes de enviá-la para o treinamento."],"metadata":{"id":"xalYfCn-OMXB"}},{"cell_type":"code","source":["class WikiArtDataset(Dataset):\n","    \"\"\"Wrapper para o dataset do Hugging Face para aplicar transformações.\"\"\"\n","    def __init__(self, hf_dataset, transform):\n","        self.hf_dataset = hf_dataset\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.hf_dataset)\n","\n","    def __getitem__(self, idx):\n","        # Garante que a imagem é RGB\n","        img = self.hf_dataset[idx]['image'].convert('RGB')\n","        return self.transform(img)"],"metadata":{"id":"0jyJhR5yNGDt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Treinar o Discriminador (GAN):\n","\n","Esta função treina o \"crítico de arte\" (Discriminador) baixando o dataset e ensinando-o a diferenciar as imagens de arte \"reais\" das imagens \"falsas\" geradas aleatoriamente pelas CPPNs."],"metadata":{"id":"a5CERwhgQjTj"}},{"cell_type":"code","source":["def train_discriminator(discriminator, cppn_template, device, img_size=64, out_channels=3, batch_size=32, epochs=5):\n","    print(\"Iniciando pré-treinamento do Discriminador...\")\n","\n","    # 1. Configurar transformações\n","    transform = transforms.Compose([\n","        transforms.Resize((img_size, img_size)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalização padrão de GAN\n","    ])\n","\n","    print(\"Carregando WikiArt\")\n","    try:\n","        raw_dataset = load_dataset(\"huggan/wikiart\", split='train')\n","    except Exception as e:\n","        print(f\"Falha ao carregar dataset: {e}. Tente verificar sua conexão.\")\n","        return discriminator\n","\n","    train_dataset = WikiArtDataset(raw_dataset, transform)\n","    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","\n","    # 3. Configurar otimizador e perda\n","    optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","    criterion = nn.BCELoss()\n","\n","    genome_size = count_params(cppn_template)\n","\n","    for epoch in range(epochs):\n","        for i, real_images in enumerate(dataloader):\n","\n","            current_batch_size = real_images.size(0)\n","            real_images = real_images.to(device)\n","\n","            # --- 1. Treinar com Imagens REAIS ---\n","            discriminator.zero_grad()\n","            labels = torch.full((current_batch_size, 1), 1.0, device=device)\n","\n","            output = discriminator(real_images)\n","            loss_real = criterion(output, labels)\n","            loss_real.backward()\n","\n","            # --- 2. Treinar com Imagens FALSAS ---\n","            # Gerar um lote de imagens falsas de CPPNs aleatórias\n","            fake_images_list = []\n","            for _ in range(current_batch_size):\n","                # Cria uma CPPN com genoma aleatório\n","                random_genome = np.random.uniform(-5.0, 5.0, size=genome_size).astype(np.float32)\n","                rand_cppn = copy.deepcopy(cppn_template)\n","                unpack_vector_to_model(rand_cppn, random_genome)\n","                rand_cppn.to(device)\n","\n","                # Gera imagem\n","                img_np = cppn_generate_image(rand_cppn, size=img_size, out_channels=out_channels, device=device)\n","\n","                # Converte imagem numpy para tensor\n","                arr = np.asarray(img_np).astype(np.float32) / 255.0\n","                arr = arr.transpose(2,0,1)[None, ...] # (1, C, H, W)\n","                fake_images_list.append(torch.from_numpy(arr))\n","\n","            fake_images = torch.cat(fake_images_list, dim=0).to(device).float()\n","\n","            # Aplicar normalização de GAN às imagens falsas\n","            fake_images = (fake_images - 0.5) / 0.5\n","\n","            labels.fill_(0.0)\n","            output = discriminator(fake_images.detach())\n","            loss_fake = criterion(output, labels)\n","            loss_fake.backward()\n","\n","            # --- 3. Atualizar Pesos ---\n","            loss_d = loss_real + loss_fake\n","            optimizer.step()\n","\n","            if i % 100 == 0:\n","                print(f\"Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{len(dataloader)}], \"\n","                      f\"Loss D: {loss_d.item():.4f} (Real: {loss_real.item():.4f}, Fake: {loss_fake.item():.4f})\")\n","\n","    print(\"Treinamento do Discriminador concluído.\")\n","    return discriminator"],"metadata":{"id":"0Ub1xvkpQhEC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Criação da CPPN:\n","\n","Este código define a rede neural (CPPN) que, ao receber coordenadas de pixels (x, y), usa as funções matemáticas Seno e Gaussiana para gerar os padrões abstratos e coloridos (RGB) que formam a imagem final."],"metadata":{"id":"9qQnsF1ZRGjP"}},{"cell_type":"code","source":["# Funções de ativação\n","class Sin(nn.Module):\n","    def forward(self, x):\n","        return torch.sin(x)\n","\n","class Gaussian(nn.Module):\n","    def forward(self, x):\n","        return torch.exp(-x**2)\n","\n","class CPPN(nn.Module):\n","    def __init__(self, out_channels=3):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(2, 8),\n","            Sin(),\n","            nn.Linear(8, 8),\n","            Gaussian(),\n","            nn.Linear(8, out_channels),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, coords):\n","        return self.net(coords)"],"metadata":{"id":"S6-swRYJRMof"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Essas funções traduzem os pesos da rede neural (CPPN) para um vetor 1D (genoma) que o algoritmo genético (NSGA-II) possa entender, e depois \"traduzem\" o genoma evoluído de volta para uma rede neural para que ela possa gerar uma imagem."],"metadata":{"id":"h-i-_Br4SJup"}},{"cell_type":"code","source":["def count_params(model):\n","    return sum(p.numel() for p in model.parameters())\n","\n","\n","def pack_params_to_vector(model):\n","    \"\"\"Retorna um vetor 1D com todos os parâmetros do modelo\"\"\"\n","    with torch.no_grad():\n","        params = [p.view(-1).cpu().numpy() for p in model.parameters()]\n","    return np.concatenate(params).astype(np.float32)\n","\n","\n","def unpack_vector_to_model(model, vector):\n","    \"\"\"Escreve os valores do vetor (numpy) nos parâmetros do modelo\"\"\"\n","    pointer = 0\n","    with torch.no_grad():\n","        for p in model.parameters():\n","            num = p.numel()\n","            slice_ = vector[pointer: pointer + num]\n","            p.copy_(torch.from_numpy(slice_.reshape(p.shape)).to(p.device))\n","            pointer += num\n","    assert pointer == len(vector)"],"metadata":{"id":"MlRhPk2ZSKB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Configuração da GAN:\n","\n","Este código define a arquitetura do Discriminador como uma rede neural convolucional simples que recebe uma imagem e devolve um único \"score\" entre 0 (totalmente falso) e 1 (totalmente real)."],"metadata":{"id":"X4-VBd0cS24M"}},{"cell_type":"code","source":["class SimpleDisc(nn.Module):\n","    def __init__(self, in_channels=3):\n","        super().__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels, 16, 4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(16, 32, 4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2),\n","            nn.AdaptiveAvgPool2d(1)\n","        )\n","        self.head = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        # x: (B, C, H, W)\n","        f = self.features(x).view(x.size(0), -1)\n","        return torch.sigmoid(self.head(f))  # [0,1] score"],"metadata":{"id":"c7ttc2IIS3EV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Criação das Imagens:\n","\n","A (make_coordinate_grid) cria uma lista com as coordenadas (x, y) de cada pixel, nesse caso, 4096 coordenadas para uma imagem 64x64.\n","\n","A (cppn_generate_image) pega essa lista de coordenadas, passa ela pela rede CPPN, e recebe de volta a cor (RGB) para cada pixel. Por fim, ela junta essas cores para montar a imagem final e a converte para o formato 0-255."],"metadata":{"id":"NxKBgkYeTaqw"}},{"cell_type":"code","source":["def make_coordinate_grid(size, device='cpu'):\n","    xs = np.linspace(-1, 1, size)\n","    ys = np.linspace(-1, 1, size)\n","    X, Y = np.meshgrid(xs, ys)\n","    coords = np.stack([X.ravel(), Y.ravel()], axis=-1).astype(np.float32)\n","    return torch.from_numpy(coords).to(device)\n","\n","\n","def cppn_generate_image(cppn_model, size=64, out_channels=1, device='cpu'):\n","    coords = make_coordinate_grid(size, device=device)\n","    with torch.no_grad():\n","        out = cppn_model(coords)\n","    img = out.cpu().numpy().reshape(size, size, out_channels)\n","\n","    img = (img * 255).clip(0, 255).astype(np.uint8)\n","    if out_channels == 1:\n","        img = img.squeeze(-1)\n","    return img"],"metadata":{"id":"kvwNxAoFTa1k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Objetivos da Evolução:\n","\n","(discriminator_score_from_image) calcula o score de realismo, o quão artística a imagem parece para o crítico, e (diversity_metric) calcula a complexidade visual da imagem pelo desvio padrão dos pixels."],"metadata":{"id":"htba7RCgUTmM"}},{"cell_type":"code","source":["def discriminator_score_from_image(discriminator, image_np, device='cpu'):\n","    arr = np.asarray(image_np).astype(np.float32) / 255.0\n","    if arr.ndim == 2:\n","        arr = arr[None, None, ...]  # (1,1,H,W)\n","    else:\n","        arr = arr.transpose(2,0,1)[None, ...]\n","\n","    tensor = torch.from_numpy(arr).to(device).float()\n","    tensor = (tensor - 0.5) / 0.5\n","\n","    with torch.no_grad():\n","        score = discriminator(tensor).cpu().item()\n","    return score\n","\n","\n","def diversity_metric(image_np):\n","    arr = np.asarray(image_np).astype(np.float32) / 255.0\n","    return float(arr.std())"],"metadata":{"id":"kq-OHTkmUTw6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Teste de Sobrevivencia:\n","\n","Esta classe define o teste de aptidão para o algoritmo genético. Para cada genoma da população, ela gera a imagem correspondente, calcula as notas de realismo e diversidade e as entrega ao otimizador, que então decide quais são os melhores."],"metadata":{"id":"IgeMSnTRVE6n"}},{"cell_type":"code","source":["class CPPN_Evolution_Problem(Problem):\n","    def __init__(self, genome_size, discriminator, cppn_template, size=64, out_channels=1, device='cpu'):\n","        super().__init__(n_var=genome_size, n_obj=2, n_constr=0, xl=-5.0, xu=5.0)\n","        self.discriminator = discriminator\n","        self.cppn_template = cppn_template\n","        self.size = size\n","        self.out_channels = out_channels\n","        self.device = device\n","\n","    def _evaluate(self, X, out, *args, **kwargs):\n","\n","        pop_size = X.shape[0]\n","        f1 = np.zeros((pop_size,))\n","        f2 = np.zeros((pop_size,))\n","\n","        for i in range(pop_size):\n","            genome = X[i]\n","            cppn = copy.deepcopy(self.cppn_template)\n","\n","            unpack_vector_to_model(cppn, genome)\n","            cppn.to(self.device)\n","            img = cppn_generate_image(cppn, size=self.size, out_channels=self.out_channels, device=self.device)\n","\n","            try:\n","                score = discriminator_score_from_image(self.discriminator, img, device=self.device)\n","            except Exception:\n","                score = 0.0\n","\n","            div = diversity_metric(img)\n","            f1[i] = -score\n","            f2[i] = -div\n","\n","        out['F'] = np.column_stack([f1, f2])"],"metadata":{"id":"S3HsuwTGVFGS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Principal:\n","\n","Cria os modelos CPPN e Discriminador e configura o problema de evolução (teste de aptidão) e inicia o algoritmo NSGA-II para evoluir os artistas CPPN, devolvendo os melhores resultados no final."],"metadata":{"id":"dS8JBRKLWBK7"}},{"cell_type":"code","source":["def run_evolution(pop_size=20, generations=30, img_size=64, out_channels=3, device='cpu'):\n","\n","    DISCRIMINATOR_PATH = \"discriminator_wikiart.pth\"\n","\n","    cppn_template = CPPN(out_channels=out_channels).to(device)\n","    genome_size = count_params(cppn_template)\n","    print(f\"Genome size: {genome_size} (para {out_channels} canais)\")\n","\n","    discriminator = SimpleDisc(in_channels=out_channels).to(device)\n","\n","    if os.path.exists(DISCRIMINATOR_PATH):\n","        print(f\"Carregando discriminador pré-treinado de {DISCRIMINATOR_PATH}...\")\n","        discriminator.load_state_dict(torch.load(DISCRIMINATOR_PATH))\n","    else:\n","        print(\"Nenhum discriminador pré-treinado encontrado. Iniciando treinamento...\")\n","\n","        discriminator = train_discriminator(discriminator,\n","                                          cppn_template,\n","                                          device,\n","                                          img_size=img_size,\n","                                          out_channels=out_channels,\n","                                          epochs=5)\n","\n","\n","        torch.save(discriminator.state_dict(), DISCRIMINATOR_PATH)\n","        print(f\"Discriminador treinado e salvo em {DISCRIMINATOR_PATH}\")\n","\n","    # Coloca o discriminador em modo de avaliação\n","    discriminator.eval()\n","\n","    # 4) definir problema\n","    problem = CPPN_Evolution_Problem(genome_size=genome_size,\n","                                     discriminator=discriminator,\n","                                     cppn_template=cppn_template,\n","                                     size=img_size,\n","                                     out_channels=out_channels,\n","                                     device=device)\n","\n","    # 5) algoritmo NSGA-II\n","    algorithm = NSGA2(pop_size=pop_size)\n","    termination = get_termination(\"n_gen\", generations)\n","\n","    print(\"\\nIniciando evolução (NSGA-II)...\")\n","    res = minimize(problem,\n","                   algorithm,\n","                   termination,\n","                   seed=1,\n","                   save_history=False,\n","                   verbose=True)\n","\n","    return res"],"metadata":{"id":"skkZl9jzWBVb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Iniciar:\n","\n","Define os parâmetros principais, como tamanho da população e número de gerações, chama a função (run_evolution) para executar todo o processo de evolução e pega os 10 melhores genomas resultantes e os utiliza para gerar e salvar as imagens finais na pasta out_evolved."],"metadata":{"id":"0WKzOyUEXL31"}},{"cell_type":"code","source":["if __name__ == '__main__':\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    print('Device:', device)\n","\n","    POP = 30\n","    GENS = 20\n","    IMG_SIZE = 64\n","    OUT_CH = 3\n","\n","    res = run_evolution(pop_size=POP, generations=GENS, img_size=IMG_SIZE, out_channels=OUT_CH, device=device)\n","\n","    os.makedirs('out_evolved', exist_ok=True)\n","    for i, genome in enumerate(res.X[:10]):\n","        cppn_template = CPPN(out_channels=OUT_CH)\n","        unpack_vector_to_model(cppn_template, genome)\n","        img = cppn_generate_image(cppn_template, size=IMG_SIZE, out_channels=OUT_CH, device=device)\n","        im = Image.fromarray(img)\n","        im.save(f'out_evolved/ind_{i}.png')\n","\n","    print('Evolução finalizada. Imagens salvas em ./out_evolved/')"],"metadata":{"id":"H7bMEWajXLqW"},"execution_count":null,"outputs":[]}]}