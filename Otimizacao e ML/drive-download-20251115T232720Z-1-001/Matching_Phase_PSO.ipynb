{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyO59lBqmNfwdH+Odpqum3wg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Otimização do PSO\n","\n","Aplicar a otimização utilizando o método \"enxame de partículas\", nesse caso, multiobjetivo.\n","\n","# Bibliotecas"],"metadata":{"id":"zwiYNMfzsNJI"}},{"cell_type":"code","source":["!pip install torch torchvision pymoo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"yqGYfteWsqiW","executionInfo":{"status":"ok","timestamp":1762609283147,"user_tz":180,"elapsed":7723,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}},"outputId":"d619cd9a-69ca-47a9-df99-36a442eb5ab7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n","Collecting pymoo\n","  Downloading pymoo-0.6.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n","Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.16.3)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.12/dist-packages (from pymoo) (3.10.0)\n","Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.12/dist-packages (from pymoo) (1.8.0)\n","Collecting cma>=3.2.2 (from pymoo)\n","  Downloading cma-4.4.0-py3-none-any.whl.metadata (8.7 kB)\n","Collecting alive-progress (from pymoo)\n","  Downloading alive_progress-3.3.0-py3-none-any.whl.metadata (72 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from pymoo) (0.3.8)\n","Collecting Deprecated (from pymoo)\n","  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3->pymoo) (2.9.0.post0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Collecting about-time==4.2.1 (from alive-progress->pymoo)\n","  Downloading about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n","Collecting graphemeu==0.7.2 (from alive-progress->pymoo)\n","  Downloading graphemeu-0.7.2-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->pymoo) (2.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.17.0)\n","Downloading pymoo-0.6.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cma-4.4.0-py3-none-any.whl (303 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.8/303.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alive_progress-3.3.0-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading about_time-4.2.1-py3-none-any.whl (13 kB)\n","Downloading graphemeu-0.7.2-py3-none-any.whl (22 kB)\n","Downloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n","Installing collected packages: graphemeu, Deprecated, cma, about-time, alive-progress, pymoo\n","Successfully installed Deprecated-1.3.1 about-time-4.2.1 alive-progress-3.3.0 cma-4.4.0 graphemeu-0.7.2 pymoo-0.6.1.5\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","from tqdm import tqdm\n","import time\n","import os\n","from PIL import Image\n","\n","# Imports específicos para o Gerador X (Holograma)\n","from scipy.fft import fft2, ifft2"],"metadata":{"id":"ZiU2s-48seHZ","executionInfo":{"status":"ok","timestamp":1762611687746,"user_tz":180,"elapsed":697,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Mapas de Fase\n","## Polarização X:"],"metadata":{"id":"CmVg-2hBshTe"}},{"cell_type":"code","source":["def load_and_preprocess_image(image_path, target_size=(450, 450)):\n","    \"\"\"\n","    Carrega e pré-processa a imagem alvo usando PIL\n","    \"\"\"\n","    try:\n","        image = Image.open(image_path).convert('L')\n","        image = image.resize(target_size, Image.LANCZOS)\n","        image_array = np.array(image, dtype=np.float64)\n","        image_array = image_array / np.max(image_array)\n","        return image_array\n","    except FileNotFoundError:\n","        print(f\"Atenção: Imagem '{image_path}' não encontrada. Criando imagem de teste...\")\n","        target_image = np.zeros(target_size)\n","        target_image[150:300, 100:200] = 1.0\n","        target_image[150:200, 200:350] = 1.0\n","        target_image[250:300, 200:350] = 1.0\n","        return target_image\n","\n","def apply_zero_padding(image, padding_factor=2):\n","    \"\"\"\n","    Aplica zero-padding à imagem\n","    \"\"\"\n","    original_size = image.shape\n","    padded_size = (image.shape[0] * padding_factor, image.shape[1] * padding_factor)\n","    padded_image = np.zeros(padded_size, dtype=complex)\n","\n","    start_row = (padded_size[0] - original_size[0]) // 2\n","    start_col = (padded_size[1] - original_size[1]) // 2\n","    padded_image[start_row:start_row+original_size[0],\n","                 start_col:start_col+original_size[1]] = image\n","\n","    return padded_image, original_size\n","\n","def create_low_pass_filter(shape, wavelength, dx, NA):\n","    \"\"\"\n","    Cria filtro passa-baixa baseado na abertura numérica\n","    \"\"\"\n","    nx, ny = shape\n","    fx = np.fft.fftfreq(nx, dx)\n","    fy = np.fft.fftfreq(ny, dx)\n","    FX, FY = np.meshgrid(fx, fy, indexing='ij')\n","\n","    f_cutoff = NA / wavelength\n","    freq_radius = np.sqrt(FX**2 + FY**2)\n","    filter_mask = (freq_radius <= f_cutoff).astype(np.float64)\n","\n","    return filter_mask\n","\n","def angular_spectrum_propagation(U, wavelength, z, dx, filter_mask=None):\n","    \"\"\"\n","    Propaga o campo usando método do espectro angular\n","    \"\"\"\n","    k = 2 * np.pi / wavelength\n","    nx, ny = U.shape\n","\n","    fx = np.fft.fftfreq(nx, dx)\n","    fy = np.fft.fftfreq(ny, dx)\n","    FX, FY = np.meshgrid(fx, fy, indexing='ij')\n","\n","    root_term = 1 - (wavelength * FX)**2 - (wavelength * FY)**2\n","    root_term[root_term < 0] = 0\n","\n","    H = np.exp(1j * k * z * np.sqrt(root_term))\n","\n","    if filter_mask is not None:\n","        H = H * filter_mask\n","\n","    # Usa as funções fft2 e ifft2 importadas da scipy.fft\n","    U_freq = fft2(U)\n","    U_prop_freq = U_freq * H\n","    U_prop = ifft2(U_prop_freq)\n","\n","    return U_prop\n","\n","def calculate_correlation(target, reconstructed):\n","    \"\"\"\n","    Calcula a correlação de Pearson entre duas imagens (valores reais)\n","    \"\"\"\n","    target_real = np.real(target).flatten()\n","    reconstructed_real = np.real(reconstructed).flatten()\n","\n","    correlation = np.corrcoef(target_real, reconstructed_real)[0, 1]\n","\n","    if np.isnan(correlation):\n","        return 0.0\n","\n","    return float(correlation)\n","\n","def extract_center(image, original_size):\n","    \"\"\"\n","    Extrai região central da imagem (remove padding)\n","    \"\"\"\n","    nx, ny = original_size\n","    start_row = (image.shape[0] - nx) // 2\n","    start_col = (image.shape[1] - ny) // 2\n","    return image[start_row:start_row+nx, start_col:start_col+ny]\n","\n","def gerchberg_saxton_angular_spectrum(target, wavelength, z, dx, NA, num_iter=50):\n","    \"\"\"\n","    Algoritmo de Gerchberg-Saxton com espectro angular\n","    \"\"\"\n","    target_padded, original_size = apply_zero_padding(target)\n","    nx_pad, ny_pad = target_padded.shape\n","\n","    filter_mask = create_low_pass_filter((nx_pad, ny_pad), wavelength, dx, NA)\n","\n","    phase = np.random.rand(nx_pad, ny_pad) * 2 * np.pi\n","    U = target_padded * np.exp(1j * phase)\n","\n","    correlations = []\n","\n","    for i in range(num_iter):\n","        U_image = angular_spectrum_propagation(U, wavelength, z, dx, filter_mask)\n","\n","        amplitude_image = np.abs(U_image)\n","        phase_image = np.angle(U_image)\n","\n","        target_region = extract_center(target_padded, original_size)\n","        recon_region = extract_center(amplitude_image, original_size)\n","\n","        corr = calculate_correlation(target_region, recon_region)\n","        correlations.append(corr)\n","\n","        U_image_updated = target_padded * np.exp(1j * phase_image)\n","\n","        U = angular_spectrum_propagation(U_image_updated, wavelength, -z, dx, filter_mask)\n","\n","        phase_hologram = np.angle(U)\n","        U = np.exp(1j * phase_hologram)\n","\n","        if (i + 1) % 10 == 0:\n","            print(f\"  Iteração GS (X) {i+1}/{num_iter}, Correlação: {corr:.4f}\")\n","\n","    phase_final = extract_center(np.angle(U), original_size)\n","\n","    return phase_final, correlations\n"],"metadata":{"id":"-TIViYUDwsge","executionInfo":{"status":"ok","timestamp":1762610421952,"user_tz":180,"elapsed":6,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Polarização Y:"],"metadata":{"id":"NRVGonTZwh6g"}},{"cell_type":"code","source":["def generate_dammann_phase_map(\n","    P: float = 520e-9,\n","    wavelength: float = 1064e-9,\n","    supercell_pixels: int = 45,\n","    n_supercells: int = 10,\n","    iters_gs: int = 400,\n","    random_seed: int = 0,\n","    verbose: bool = True\n",") -> tuple[np.ndarray, dict, list]:\n","    \"\"\"\n","    Gera o mapa de fase para uma grade de Dammann (spot-cloud) usando o algoritmo GS.\n","    \"\"\"\n","    np.random.seed(random_seed)\n","\n","    N_super = supercell_pixels\n","    dx = P\n","    d = dx * N_super\n","\n","    kx = np.fft.fftfreq(N_super, d=dx)\n","    ky = np.fft.fftfreq(N_super, d=dx)\n","    kx_shift = np.fft.fftshift(kx)\n","    ky_shift = np.fft.fftshift(ky)\n","    KX, KY = np.meshgrid(kx_shift, ky_shift)\n","    K_rad = np.sqrt(KX**2 + KY**2)\n","    target_radius = min(1.0 / wavelength, 1.0 / (2.0 * dx))\n","    target_amp = (K_rad <= target_radius).astype(float)\n","\n","    # Algoritmo GS\n","    plane_field = np.exp(1j * 2.0 * np.pi * np.random.rand(N_super, N_super))\n","    errors = []\n","\n","    # Loop de iteração para Dammann\n","    gs_iterator = range(iters_gs)\n","    if verbose:\n","        # Cria uma barra de progresso\n","        gs_iterator = tqdm(range(iters_gs), desc=\"  Iterações GS (Y)\", leave=False)\n","\n","    for it in gs_iterator:\n","        far = np.fft.fft2(plane_field)\n","        far_shift = np.fft.fftshift(far)\n","\n","        amp_current = np.abs(far_shift)\n","        err = np.sqrt(np.mean((amp_current / (amp_current.max() + 1e-9) - target_amp)**2))\n","        errors.append(err)\n","\n","        far_shift = target_amp * np.exp(1j * np.angle(far_shift))\n","        far = np.fft.ifftshift(far_shift)\n","\n","        plane_field = np.fft.ifft2(far)\n","        plane_field = np.exp(1j * np.angle(plane_field))\n","\n","    supercell_phase = np.angle(plane_field)\n","\n","    full_phase = np.tile(supercell_phase, (n_supercells, n_supercells))\n","\n","    if verbose:\n","        print(f\"  Mapa Dammann (Y) gerado: {full_phase.shape} pixels\")\n","\n","    metrics = {}\n","\n","    return full_phase, metrics, errors"],"metadata":{"id":"wmlUx9u9whMW","executionInfo":{"status":"ok","timestamp":1762610423358,"user_tz":180,"elapsed":16,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Arquitetura do Simulador:\n","Permite que ele seja carregado e utilizado."],"metadata":{"id":"BOKVsqp3wtQB"}},{"cell_type":"code","source":["IMG_SIZE = 64\n","MAX_DIM_NM = 520\n","\n","def draw_meta_atom_ellipse(L_x_nm, L_y_nm):\n","    \"\"\" Desenha um meta-átomo de ELIPSE como um array numpy binário. \"\"\"\n","    scale_factor = IMG_SIZE / MAX_DIM_NM\n","    a_px = L_x_nm * scale_factor\n","    b_px = L_y_nm * scale_factor\n","\n","    if a_px <= 0: a_px = 1e-9\n","    if b_px <= 0: b_px = 1e-9\n","\n","    x = np.arange(0, IMG_SIZE)\n","    y = np.arange(0, IMG_SIZE)\n","    xx, yy = np.meshgrid(x, y)\n","    center = (IMG_SIZE - 1) / 2.0\n","\n","    mask = (((xx - center) / (a_px/2.0))**2 + ((yy - center) / (b_px/2.0))**2) <= 1\n","    img = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.float32)\n","    img[mask] = 1.0\n","    return img\n","\n","class ResBlock(nn.Module):\n","    \"\"\"\n","    Define um bloco ResNet básico\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        self.main_path = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","        self.shortcut_path = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.shortcut_path = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","    def forward(self, x):\n","        out = self.main_path(x) + self.shortcut_path(x)\n","        out = F.relu(out)\n","        return out\n","\n","class ResNetSimulator(nn.Module):\n","    \"\"\"\n","    Implementação do Simulator baseado em ResNet.\n","    \"\"\"\n","    N_OUTPUTS = 4 # T_x, T_y, F_x, F_y\n","    def __init__(self, in_channels=1, n_outputs=N_OUTPUTS):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(inplace=True))\n","        self.layer1 = ResBlock(64, 64, stride=1)\n","        self.layer2 = ResBlock(64, 128, stride=2)\n","        self.layer3 = ResBlock(128, 256, stride=2)\n","        self.layer4 = ResBlock(256, 256, stride=2)\n","        self.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n","        self.head = nn.Sequential(nn.Linear(256 * 2 * 2, 128), nn.ReLU(inplace=True), nn.Linear(128, n_outputs))\n","    def forward(self, x):\n","        out = self.conv1(x); out = self.layer1(out); out = self.layer2(out); out = self.layer3(out); out = self.layer4(out); out = self.avgpool(out); out = out.view(out.size(0), -1); out = self.head(out); return out\n"],"metadata":{"id":"YMbHIDC7xbNg","executionInfo":{"status":"ok","timestamp":1762610549623,"user_tz":180,"elapsed":198,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Definição do Problema:"],"metadata":{"id":"CIGbC5t6xbmV"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"5qKx-E_mrixk","executionInfo":{"status":"ok","timestamp":1762610628148,"user_tz":180,"elapsed":22,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}}},"outputs":[],"source":["class ComplexAmplitudeProblem(Problem):\n","    \"\"\"\n","    Problema de otimização que busca [L_x, L_y] para minimizar\n","    o erro de amplitude complexa (como no Artigo_Hugo.pdf).\n","    \"\"\"\n","    def __init__(self, simulator, device,\n","                 target_F_x,  # Apenas a Fase X alvo\n","                 target_F_y): # Apenas a Fase Y alvo\n","\n","        self.simulator = simulator\n","        self.device = device\n","\n","        self.target_F_x_tensor = torch.tensor(target_F_x, device=device, dtype=torch.float32)\n","        self.target_F_y_tensor = torch.tensor(target_F_y, device=device, dtype=torch.float32)\n","\n","        self.target_real_x = torch.cos(self.target_F_x_tensor)\n","        self.target_imag_x = torch.sin(self.target_F_x_tensor)\n","        self.target_real_y = torch.cos(self.target_F_y_tensor)\n","        self.target_imag_y = torch.sin(self.target_F_y_tensor)\n","\n","        super().__init__(n_var=2, n_obj=2, n_constr=0,\n","                         xl=np.array([70, 70]), #\n","                         xu=np.array([200, 200])) #\n","\n","    def _evaluate(self, X, out, *args, **kwargs):\n","        pop_size = X.shape[0]\n","        f1_batch = np.zeros(pop_size) # Erro X-pol\n","        f2_batch = np.zeros(pop_size) # Erro Y-pol\n","\n","        with torch.no_grad():\n","            for i in range(pop_size):\n","                L_x_nm, L_y_nm = X[i]\n","\n","                img_np = draw_meta_atom_ellipse(L_x_nm, L_y_nm)\n","                img_tensor = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).to(self.device)\n","\n","                preds = self.simulator(img_tensor)\n","                pred_T_x = preds[0, 0]\n","                pred_T_y = preds[0, 1]\n","                pred_F_x = preds[0, 2]\n","                pred_F_y = preds[0, 3]\n","\n","                pred_real_x = pred_T_x * torch.cos(pred_F_x)\n","                pred_imag_x = pred_T_x * torch.sin(pred_F_x)\n","                pred_real_y = pred_T_y * torch.cos(pred_F_y)\n","                pred_imag_y = pred_T_y * torch.sin(pred_F_y)\n","\n","                f1 = (pred_real_x - self.target_real_x)**2 + \\\n","                     (pred_imag_x - self.target_imag_x)**2\n","\n","                f2 = (pred_real_y - self.target_real_y)**2 + \\\n","                     (pred_imag_y - self.target_imag_y)**2\n","\n","                f1_batch[i] = f1.item()\n","                f2_batch[i] = f2.item()\n","\n","        out[\"F\"] = np.column_stack([f1_batch, f2_batch])"]},{"cell_type":"markdown","source":["## PSO Multicritério\n","\n","1. Inicializa partículas aleatórias.\n","\n","2. Avalia todos os objetivos.\n","\n","3. Mantém um repositório de soluções não dominadas (Pareto front).\n","\n","4. Move partículas em direção a líderes escolhidos do repositório.\n","\n","5. Atualiza a fronteira de Pareto.\n","\n","6. Repete até o número máximo de iterações."],"metadata":{"id":"-tNe8tfyx54C"}},{"cell_type":"code","source":["def dominates(a, b):\n","    \"\"\"Retorna True se a domina b (para minimização).\"\"\"\n","    return np.all(a <= b) and np.any(a < b)\n","\n","def pareto_front(F):\n","    \"\"\"Retorna os índices das soluções não-dominadas.\"\"\"\n","    n = F.shape[0]\n","    mask = np.ones(n, dtype=bool)\n","    for i in range(n):\n","        for j in range(n):\n","            if i != j and dominates(F[j], F[i]):\n","                mask[i] = False\n","                break\n","    return np.where(mask)[0]\n","\n","def MOPSO_custom(\n","    eval_func, n_particles=50, n_iter=100, dim=2, bounds=(-5, 5),\n","    w=0.5, c1=1.5, c2=1.5\n","):\n","    lb, ub = bounds\n","    # Garante que os limites sejam aplicados por dimensão se forem arrays\n","    if isinstance(lb, (list, np.ndarray)):\n","        lb = np.array(lb).reshape(1, dim)\n","    if isinstance(ub, (list, np.ndarray)):\n","        ub = np.array(ub).reshape(1, dim)\n","\n","    X = np.random.uniform(lb, ub, (n_particles, dim))\n","    V = np.zeros_like(X)\n","\n","    # Avaliação inicial\n","    F = eval_func(X)\n","    pbest = X.copy()\n","    F_pbest = F.copy()\n","\n","    # Arquivo (repositório Pareto)\n","    idx_pareto = pareto_front(F)\n","    archive_X = X[idx_pareto]\n","    archive_F = F[idx_pareto]\n","\n","    for it in range(n_iter):\n","        # Escolher líder aleatório do repositório\n","        leaders_idx = np.random.choice(len(archive_X), n_particles)\n","        G = archive_X[leaders_idx]\n","\n","        # Atualizar velocidade e posição\n","        r1, r2 = np.random.rand(n_particles, dim), np.random.rand(n_particles, dim)\n","        V = w*V + c1*r1*(pbest - X) + c2*r2*(G - X)\n","        X = np.clip(X + V, lb, ub)\n","\n","        F = eval_func(X)\n","\n","        for i in range(n_particles):\n","            if dominates(F[i], F_pbest[i]):\n","                pbest[i], F_pbest[i] = X[i].copy(), F[i].copy()\n","\n","        all_X = np.vstack([archive_X, X])\n","        all_F = np.vstack([archive_F, F])\n","        idx = pareto_front(all_F)\n","        archive_X, archive_F = all_X[idx], all_F[idx]\n","\n","        if len(archive_X) > 100:\n","            keep = np.random.choice(len(archive_X), 100, replace=False)\n","            archive_X, archive_F = archive_X[keep], archive_F[keep]\n","\n","    return archive_X, archive_F\n","\n","def evaluate_pixel_objectives(X_batch, simulator, device, t_F_x, t_F_y):\n","    \"\"\"\n","    Avalia um batch de partículas [L_x, L_y] para um *único* pixel alvo (t_F_x, t_F_y).\n","    \"\"\"\n","    pop_size = X_batch.shape[0]\n","    f_batch = np.zeros((pop_size, 2)) # (Erro_X, Erro_Y)\n","\n","    # Pré-calcular alvos no device (para eficiência)\n","    target_real_x = torch.cos(torch.tensor(t_F_x, device=device))\n","    target_imag_x = torch.sin(torch.tensor(t_F_x, device=device))\n","    target_real_y = torch.cos(torch.tensor(t_F_y, device=device))\n","    target_imag_y = torch.sin(torch.tensor(t_F_y, device=device))\n","\n","    with torch.no_grad():\n","        for i in range(pop_size):\n","            L_x_nm, L_y_nm = X_batch[i]\n","\n","            img_np = draw_meta_atom_ellipse(L_x_nm, L_y_nm)\n","            img_tensor = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).to(device)\n","\n","            # Passa pelo simulador\n","            preds = simulator(img_tensor)\n","            pred_T_x, pred_T_y, pred_F_x, pred_F_y = preds[0]\n","\n","            # Calcula os campos complexos (previsto vs. alvo)\n","            pred_real_x = pred_T_x * torch.cos(pred_F_x)\n","            pred_imag_x = pred_T_x * torch.sin(pred_F_x)\n","            pred_real_y = pred_T_y * torch.cos(pred_F_y)\n","            pred_imag_y = pred_T_y * torch.sin(pred_F_y)\n","\n","            # Calcula os erros (objetivos f1 e f2)\n","            f1 = (pred_real_x - target_real_x)**2 + (pred_imag_x - target_imag_x)**2\n","            f2 = (pred_real_y - target_real_y)**2 + (pred_imag_y - target_imag_y)**2\n","\n","            f_batch[i, 0] = f1.item()\n","            f_batch[i, 1] = f2.item()\n","\n","    return f_batch"],"metadata":{"id":"u9VKiNcSyVq6","executionInfo":{"status":"ok","timestamp":1762611098911,"user_tz":180,"elapsed":30,"user":{"displayName":"João Pedro Casalli","userId":"01470765541431062123"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ===================================================================\n","# --- Bloco 4: Execução Principal (Otimização) ---\n","# ===================================================================\n","if __name__ == \"__main__\":\n","\n","    # --- 1. Parâmetros Fixos ---\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    # Parâmetros de Geração (X - Holograma)\n","    IMG_ALVO_X = '/content/WhatsApp Image 2025-11-06 at 16.18.47.png' # Nome do arquivo de imagem\n","    TAMANHO_ALVO_X = (45, 45) # Tamanho final da metasuperfície\n","    PARAMS_GS_X = {\n","        'wavelength': 1064e-9, #\n","        'z': 380e-6,           #\n","        'dx': 520e-9,          #\n","        'NA': 0.65,            #\n","        'num_iter': 50         #\n","    }\n","\n","    # Parâmetros de Geração (Y - Dammann)\n","    PARAMS_GS_Y = {\n","        'P': 520e-9,                       #\n","        'wavelength': 1064e-9,\n","        'supercell_pixels': 45,\n","        'n_supercells': TAMANHO_ALVO_X[0] // 45, # (450 // 45 = 10)\n","        'iters_gs': 400,\n","        'verbose': True\n","    }\n","\n","    CAMINHO_SIMULADOR = '/content/simulator_teste_2,.pth' #\n","    POP_SIZE_AG = 20\n","    GERACOES_AG = 40\n","\n","    # Geração dos Mapas de Fase\n","    print(f\"Usando dispositivo: {device}\")\n","\n","    print(f\"\\n--- Etapa 1: Gerando Fase X (Holograma) de '{IMG_ALVO_X}' ---\")\n","    target_image_x = load_and_preprocess_image(IMG_ALVO_X, target_size=TAMANHO_ALVO_X)\n","    target_map_Fase_X, _ = gerchberg_saxton_angular_spectrum(\n","        target_image_x, **PARAMS_GS_X\n","    )\n","    MAP_H, MAP_W = target_map_Fase_X.shape\n","    print(f\"Mapa X gerado: {target_map_Fase_X.shape}\")\n","\n","    print(f\"\\n--- Etapa 2: Gerando Fase Y (Dammann) ---\")\n","    target_map_Fase_Y, _, _ = generate_dammann_phase_map(**PARAMS_GS_Y)\n","\n","    if target_map_Fase_Y.shape != (MAP_H, MAP_W):\n","        print(f\"ERRO: O shape do mapa Y {target_map_Fase_Y.shape} não bate com o do mapa X {(MAP_H, MAP_W)}!\")\n","        exit()\n","\n","    # Carregar Simulador\n","    print(f\"\\n--- Etapa 3: Carregando simulador de '{CAMINHO_SIMULADOR}' ---\")\n","    if not os.path.exists(CAMINHO_SIMULADOR):\n","        print(f\"ERRO: Arquivo do simulador '{CAMINHO_SIMULADOR}' não encontrado.\")\n","        print(\"Por favor, treine o simulador (parte 1 do notebook) primeiro.\")\n","        exit()\n","\n","    simulator = ResNetSimulator(in_channels=1, n_outputs=4).to(device)\n","    simulator.load_state_dict(torch.load(CAMINHO_SIMULADOR, map_location=device))\n","    simulator.eval()\n","    print(\"Simulador carregado.\")\n","\n","    print(f\"\\n--- Etapa 4: Iniciando otimização pixel-a-pixel (com MOPSO Customizado) ---\")\n","    print(f\"Tamanho do mapa: {MAP_H}x{MAP_W} ({MAP_H*MAP_W} pixels)\")\n","\n","    POP_SIZE_PSO = POP_SIZE_AG\n","    ITERACOES_PSO = GERACOES_AG\n","\n","    print(f\"Parâmetros PSO: {POP_SIZE_PSO} partículas, {ITERACOES_PSO} iterações por pixel\")\n","\n","    metasurface_design_Lx = np.zeros((MAP_H, MAP_W))\n","    metasurface_design_Ly = np.zeros((MAP_H, MAP_W))\n","    metasurface_pixel_errors = np.zeros((MAP_H, MAP_W, 2)) # 2 objetivos de erro\n","\n","    # (Não precisamos mais do 'algorithm', 'termination' ou 'ComplexAmplitudeProblem' do pymoo)\n","\n","    start_time_total = time.time()\n","\n","    for r in tqdm(range(MAP_H), desc=\"Otimizando Linhas\"):\n","        for c in range(MAP_W):\n","            t_F_x = target_map_Fase_X[r, c]\n","            t_F_y = target_map_Fase_Y[r, c]\n","\n","            # 1. Definir os limites (bounds)\n","            #    (Baseado nos seus limites [70, 70] e [200, 200] do Pymoo)\n","            lim_inferior = np.array([70, 70])\n","            lim_superior = np.array([200, 200])\n","\n","            # 2. Criar a função de avaliação \"on-the-fly\"\n","            #    Usamos uma função lambda para \"capturar\" os alvos (t_F_x, t_F_y)\n","            #    e passá-los para a nossa função \"ponte\".\n","            #    (cap_... = captura o valor atual do loop)\n","            eval_func_pixel = lambda x_batch, cap_t_F_x=t_F_x, cap_t_F_y=t_F_y: evaluate_pixel_objectives(\n","                x_batch, simulator, device, cap_t_F_x, cap_t_F_y\n","            )\n","\n","            # 3. Chamar o seu MOPSO\n","            pareto_X, pareto_F = MOPSO_custom(\n","                eval_func=eval_func_pixel,\n","                n_particles=POP_SIZE_PSO,\n","                n_iter=ITERACOES_PSO,\n","                dim=2, # (L_x, L_y)\n","                bounds=(lim_inferior, lim_superior), # Passando os limites\n","                w=0.5, c1=1.5, c2=1.5 # (Parâmetros padrão do seu PSO)\n","            )\n","\n","            # 4. Selecionar o melhor da fronteira (exatamente a mesma lógica)\n","            errors = pareto_F\n","            norms = np.linalg.norm(errors, axis=1) # Distância Euclidiana 2D\n","            best_index = np.argmin(norms)\n","            best_geometry = pareto_X[best_index] # [L_x, L_y]\n","            best_errors = pareto_F[best_index]   # [Error_X, Error_Y]\n","\n","            # 5. Armazenar resultados\n","            metasurface_design_Lx[r, c] = best_geometry[0]\n","            metasurface_design_Ly[r, c] = best_geometry[1]\n","            metasurface_pixel_errors[r, c, :] = best_errors\n","\n","    end_time_total = time.time()\n","    total_time_min = (end_time_total - start_time_total) / 60\n","    print(f\"\\nOtimização de {MAP_H*MAP_W} pixels concluída em {total_time_min:.2f} minutos.\")\n","\n","    # --- 5. Salvar Resultados ---\n","    print(\"Salvando design final...\")\n","    np.save(\"metasurface_design_Lx_final.npy\", metasurface_design_Lx)\n","    np.save(\"metasurface_design_Ly_final.npy\", metasurface_design_Ly)\n","    np.save(\"metasurface_pixel_errors_final.npy\", metasurface_pixel_errors)\n","\n","    print(\"Resultados salvos em 'metasurface_design_Lx_final.npy' e 'metasurface_design_Ly_final.npy'\")\n","\n","    # --- 6. Gerar e Salvar Gráficos ---\n","    print(\"\\n--- Etapa 5: Gerando gráficos dos resultados ---\")\n","\n","    # Carrega os resultados salvos\n","    final_Lx = np.load(\"metasurface_design_Lx_final.npy\")\n","    final_Ly = np.load(\"metasurface_design_Ly_final.npy\")\n","    final_errors = np.load(\"metasurface_pixel_errors_final.npy\")\n","\n","\n","    # --- Gráfico 1: Design Físico (Lx e Ly) ---\n","    # (Similar a image_1d08c0.jpg)\n","\n","    # Usa os limites do otimizador (xl, xu) para definir a escala de cores\n","    vmin_val = 70\n","    vmax_val = 200\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n","    fig.suptitle(\"Design Físico Final da Metassuperfície\", fontsize=16)\n","\n","    # Plot L_x\n","    im1 = ax1.imshow(final_Lx, cmap='viridis', vmin=vmin_val, vmax=vmax_val)\n","    ax1.set_title(\"Distribuição de L_x\")\n","    ax1.set_xlabel(\"Pixel (coluna)\")\n","    ax1.set_ylabel(\"Pixel (linha)\")\n","    fig.colorbar(im1, ax=ax1, label=\"Comprimento Lx (nm)\")\n","\n","    # Plot L_y\n","    im2 = ax2.imshow(final_Ly, cmap='viridis', vmin=vmin_val, vmax=vmax_val)\n","    ax2.set_title(\"Distribuição de L_y\")\n","    ax2.set_xlabel(\"Pixel (coluna)\")\n","    fig.colorbar(im2, ax=ax2, label=\"Comprimento Ly (nm)\")\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","    plt.savefig(\"plot_design_fisico_final.png\")\n","    print(\"Gráfico 'plot_design_fisico_final.png' salvo.\")\n","\n","\n","    # --- Gráfico 2: Mapa de Erro ---\n","    # (Similar a image_1d07e2.jpg)\n","\n","    # O arquivo de erro tem shape (H, W, 2). Calculamos a norma Euclidiana\n","    # (distância) para ter um único valor de erro por pixel.\n","    error_norm = np.linalg.norm(final_errors, axis=2)\n","\n","    plt.figure(figsize=(7, 6))\n","    plt.imshow(error_norm, cmap='afmhot') # 'afmhot' é similar ao 'hot' da sua imagem\n","    plt.title(\"Mapa de Erro do Casamento de Fase\")\n","    plt.xlabel(\"Pixel (coluna)\")\n","    plt.ylabel(\"Pixel (linha)\")\n","    plt.colorbar(label=\"Erro (Norma Euclidiana)\")\n","    plt.tight_layout()\n","    plt.savefig(\"plot_mapa_erro_final.png\")\n","    print(\"Gráfico 'plot_mapa_erro_final.png' salvo.\")\n","\n","\n","    # --- Gráfico 3: Validação da Reconstrução ---\n","    # (Similar a image_1d0539.jpg)\n","\n","    # Para criar este gráfico, precisamos simular a propagação\n","    # usando o design final (Lx, Ly) que acabamos de otimizar.\n","\n","    print(\"Iniciando validação da reconstrução (pode levar um momento)...\")\n","\n","    # Prepara arrays para guardar a fase e amplitude reais do design\n","    achieved_phase_X = np.zeros((MAP_H, MAP_W))\n","    achieved_amplitude_X = np.zeros((MAP_H, MAP_W))\n","\n","    # Garante que o simulador está em modo de avaliação\n","    simulator.eval()\n","    with torch.no_grad():\n","        # Itera por cada pixel do design final\n","        for r in tqdm(range(MAP_H), desc=\"  Validando design\", leave=False):\n","            for c in range(MAP_W):\n","                L_x_nm = final_Lx[r, c]\n","                L_y_nm = final_Ly[r, c]\n","\n","                # Desenha o meta-átomo e passa pelo simulador (ResNet)\n","                img_np = draw_meta_atom_ellipse(L_x_nm, L_y_nm)\n","                img_tensor = torch.from_numpy(img_np).unsqueeze(0).unsqueeze(0).to(device)\n","                preds = simulator(img_tensor)\n","\n","                # Armazena a amplitude (T_x) e fase (F_x) previstas\n","                achieved_amplitude_X[r, c] = preds[0, 0].item()\n","                achieved_phase_X[r, c] = preds[0, 2].item()\n","\n","    # Cria o campo complexo no plano da metassuperfície\n","    U_start_plane = achieved_amplitude_X * np.exp(1j * achieved_phase_X)\n","\n","    # Aplica padding\n","    U_padded, original_size = apply_zero_padding(U_start_plane)\n","    nx_pad, ny_pad = U_padded.shape\n","\n","    # Pega os parâmetros de propagação da Etapa 1\n","    params_x = PARAMS_GS_X\n","\n","    # Cria o filtro passa-baixa (exatamente como no algoritmo GS)\n","    filter_mask = create_low_pass_filter(\n","        (nx_pad, ny_pad),\n","        params_x['wavelength'],\n","        params_x['dx'],\n","        params_x['NA']\n","    )\n","\n","    # Propaga o campo usando o Espectro Angular\n","    U_image_reconstructed = angular_spectrum_propagation(\n","        U_padded,\n","        params_x['wavelength'],\n","        params_x['z'],\n","        params_x['dx'],\n","        filter_mask\n","    )\n","\n","    # Extrai a amplitude da região central (remove o padding)\n","    recon_amplitude_final = np.abs(extract_center(U_image_reconstructed, original_size))\n","\n","    # Plota a imagem alvo original (que já está na memória) vs. a reconstrução\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n","    fig.suptitle(\"Validação Final da Reconstrução\", fontsize=16)\n","\n","    # Imagem Alvo (target_image_x foi carregada na Etapa 1)\n","    ax1.imshow(target_image_x, cmap='gray')\n","    ax1.set_title(f\"Imagem Alvo Original ({MAP_H}x{MAP_W})\")\n","\n","    # Imagem Reconstruída\n","    ax2.imshow(recon_amplitude_final, cmap='gray')\n","    ax2.set_title(f\"Imagem Reconstruída ({MAP_H}x{MAP_W})\")\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","    plt.savefig(\"plot_validacao_reconstrucao.png\")\n","    print(\"Gráfico 'plot_validacao_reconstrucao.png' salvo.\")\n","    print(\"--- Geração de gráficos concluída! ---\")\n","\n","    print(\"Script concluído.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKsT4xCZx5Nf","outputId":"130442c0-c807-4d82-cf86-fc62084b47b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Usando dispositivo: cpu\n","\n","--- Etapa 1: Gerando Fase X (Holograma) de '/content/WhatsApp Image 2025-11-06 at 16.18.47.png' ---\n","  Iteração GS (X) 10/50, Correlação: 0.6094\n","  Iteração GS (X) 20/50, Correlação: 0.6418\n","  Iteração GS (X) 30/50, Correlação: 0.6569\n","  Iteração GS (X) 40/50, Correlação: 0.6725\n","  Iteração GS (X) 50/50, Correlação: 0.6760\n","Mapa X gerado: (45, 45)\n","\n","--- Etapa 2: Gerando Fase Y (Dammann) ---\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["  Mapa Dammann (Y) gerado: (45, 45) pixels\n","\n","--- Etapa 3: Carregando simulador de '/content/simulator_teste_2,.pth' ---\n","Simulador carregado.\n","\n","--- Etapa 4: Iniciando otimização pixel-a-pixel (com MOPSO Customizado) ---\n","Tamanho do mapa: 45x45 (2025 pixels)\n","Parâmetros PSO: 20 partículas, 40 iterações por pixel\n"]},{"output_type":"stream","name":"stderr","text":["\rOtimizando Linhas:   0%|          | 0/45 [00:00<?, ?it/s]"]}]}]}