{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyPLIM3+d5ERAFwiF8Wd1kv1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EjasmFwpByJh"},"outputs":[],"source":["\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import random\n","import time\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm\n","from PIL import Image\n","from joblib import Parallel, delayed\n","from scipy.fft import fft2, ifft2, fftshift, ifftshift\n","from deap import base, creator, tools, algorithms\n","\n","\"\"\"## Estruturas para utilizar o Simulador e o Gerador\"\"\"\n","\n","class ResBlock(nn.Module):\n","    \"\"\"\n","    Define um bloco ResNet b√É¬°sico\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","\n","        self.main_path = nn.Sequential(\n","\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(out_channels)\n","        )\n","\n","        self.shortcut_path = nn.Sequential()\n","\n","        if stride != 1 or in_channels != out_channels:\n","            self.shortcut_path = nn.Sequential(\n","\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        out = self.main_path(x) + self.shortcut_path(x)\n","        out = F.relu(out)\n","        return out\n","\n","# N_OUTPUTS √É¬© quantos valores se quer prever\n","N_OUTPUTS = 4\n","\n","class ResNetSimulator(nn.Module):\n","    \"\"\"\n","    Implementa√É¬ß√É¬£o do Simulator baseado em ResNet.\n","    \"\"\"\n","    def __init__(self, in_channels=1, n_outputs=N_OUTPUTS):\n","        super().__init__()\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.layer1 = ResBlock(64, 64, stride=1)\n","\n","        self.layer2 = ResBlock(64, 128, stride=2)\n","\n","        self.layer3 = ResBlock(128, 256, stride=2)\n","\n","        self.layer4 = ResBlock(256, 256, stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n","\n","        self.head = nn.Sequential(\n","            nn.Linear(256 * 2 * 2, 128),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(128, n_outputs)\n","        )\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = self.avgpool(out)\n","        out = out.view(out.size(0), -1)\n","        out = self.head(out)\n","        return out\n","\n","class Sin(nn.Module):\n","    def forward(self, x): return torch.sin(x)\n","\n","class Gaussian(nn.Module):\n","    def forward(self, x): return torch.exp(-x**2)\n","\n","def make_coordinate_grid(size, device='cpu'):\n","    \"\"\"Cria grade de coordenadas (x, y)\"\"\"\n","    xs = np.linspace(-1, 1, size)\n","    ys = np.linspace(-1, 1, size)\n","    xx, yy = np.meshgrid(xs, ys)\n","\n","    coords = np.stack([xx.ravel(), yy.ravel()], axis=-1).astype(np.float32)\n","    return torch.from_numpy(coords).to(device) # shape (size*size, 2)\n","\n","class CPPN_Generator(nn.Module):\n","    \"\"\"\n","    Gerador CPPN. Mapeia (vetor latente 'v' + coords 'x,y,r') -> pixel.\n","    \"\"\"\n","    def __init__(self, latent_dim, in_coords=2, out_channels=1, hidden_dim=64):\n","            super().__init__()\n","            self.latent_dim = latent_dim\n","            self.in_coords = in_coords\n","            self.out_channels = out_channels\n","\n","            input_dim = in_coords + latent_dim\n","\n","            self.net = nn.Sequential(\n","                nn.Linear(input_dim, hidden_dim),\n","                nn.Tanh(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.ReLU(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                Sin(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.LeakyReLU(0.2),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                Gaussian(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.Tanh(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                Sin(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                Gaussian(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.Tanh(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                nn.ReLU(),\n","\n","                nn.Linear(hidden_dim, hidden_dim),\n","                Sin(),\n","\n","                nn.Linear(hidden_dim, out_channels),\n","                nn.Sigmoid()\n","            )\n","\n","    def forward(self, coords, v):\n","\n","        v_expanded = v.unsqueeze(1)\n","        v_tiled = v_expanded.repeat(1, coords.size(0), 1)\n","\n","        coords_tiled = coords.unsqueeze(0).repeat(v.size(0), 1, 1)\n","\n","        combined_input = torch.cat([coords_tiled, v_tiled], dim=-1)\n","\n","        output = self.net(combined_input)\n","\n","        img_size = int(np.sqrt(coords.size(0)))\n","\n","        output = output.permute(0, 2, 1).view(-1, self.out_channels, img_size, img_size)\n","\n","        return output\n","\n","\"\"\"# Mapas de Fase\n","\n","Cria√É¬ß√É¬£o do mapa de fase para a polariza√É¬ß√É¬£o x:\n","\"\"\"\n","\n","def load_and_preprocess_image(image_path, target_size=(450, 450)):\n","    \"\"\"\n","    Carrega e pr√É¬©-processa a imagem alvo usando PIL\n","    \"\"\"\n","    try:\n","        image = Image.open(image_path).convert('L')\n","        image = image.resize(target_size, Image.LANCZOS)\n","        image_array = np.array(image, dtype=np.float64)\n","        image_array = image_array / np.max(image_array)\n","        return image_array\n","    except FileNotFoundError:\n","        print(f\"Aten√É¬ß√É¬£o: Imagem '{image_path}' n√É¬£o encontrada. Criando imagem de teste...\")\n","        target_image = np.zeros(target_size)\n","        target_image[150:300, 100:200] = 1.0\n","        target_image[150:200, 200:350] = 1.0\n","        target_image[250:300, 200:350] = 1.0\n","        return target_image\n","\n","def apply_zero_padding(image, padding_factor=2):\n","    \"\"\"\n","    Aplica zero-padding √É¬† imagem\n","    \"\"\"\n","    original_size = image.shape\n","    padded_size = (image.shape[0] * padding_factor, image.shape[1] * padding_factor)\n","    padded_image = np.zeros(padded_size, dtype=complex)\n","\n","    start_row = (padded_size[0] - original_size[0]) // 2\n","    start_col = (padded_size[1] - original_size[1]) // 2\n","    padded_image[start_row:start_row+original_size[0],\n","                 start_col:start_col+original_size[1]] = image\n","\n","    return padded_image, original_size\n","\n","def create_low_pass_filter(shape, wavelength, dx, NA):\n","    \"\"\"\n","    Cria filtro passa-baixa baseado na abertura num√É¬©rica\n","    \"\"\"\n","    nx, ny = shape\n","    fx = np.fft.fftfreq(nx, dx)\n","    fy = np.fft.fftfreq(ny, dx)\n","    FX, FY = np.meshgrid(fx, fy, indexing='ij')\n","\n","    f_cutoff = NA / wavelength\n","    freq_radius = np.sqrt(FX**2 + FY**2)\n","    filter_mask = (freq_radius <= f_cutoff).astype(np.float64)\n","\n","    return filter_mask\n","\n","def angular_spectrum_propagation(U, wavelength, z, dx, filter_mask=None):\n","    \"\"\"\n","    Propaga o campo usando m√É¬©todo do espectro angular\n","    \"\"\"\n","    k = 2 * np.pi / wavelength\n","    nx, ny = U.shape\n","\n","    fx = np.fft.fftfreq(nx, dx)\n","    fy = np.fft.fftfreq(ny, dx)\n","    FX, FY = np.meshgrid(fx, fy, indexing='ij')\n","\n","    root_term = 1 - (wavelength * FX)**2 - (wavelength * FY)**2\n","    root_term[root_term < 0] = 0\n","\n","    H = np.exp(1j * k * z * np.sqrt(root_term))\n","\n","    if filter_mask is not None:\n","        H = H * filter_mask\n","\n","    U_freq = fft2(U)\n","    U_prop_freq = U_freq * H\n","    U_prop = ifft2(U_prop_freq)\n","\n","    return U_prop\n","\n","def calculate_correlation(target, reconstructed):\n","    \"\"\"\n","    Calcula a correla√É¬ß√É¬£o de Pearson entre duas imagens (valores reais)\n","    \"\"\"\n","    target_real = np.real(target).flatten()\n","    reconstructed_real = np.real(reconstructed).flatten()\n","\n","    correlation = np.corrcoef(target_real, reconstructed_real)[0, 1]\n","\n","    if np.isnan(correlation):\n","        return 0.0\n","\n","    return float(correlation)\n","\n","def extract_center(image, original_size):\n","    \"\"\"\n","    Extrai regi√É¬£o central da imagem (remove padding)\n","    \"\"\"\n","    nx, ny = original_size\n","    start_row = (image.shape[0] - nx) // 2\n","    start_col = (image.shape[1] - ny) // 2\n","    return image[start_row:start_row+nx, start_col:start_col+ny]\n","\n","def reconstruct_image(phase_map, wavelength, z, dx, NA):\n","    \"\"\"\n","    Reconstr√É¬≥i a imagem a partir do mapa de fase\n","    \"\"\"\n","    # Aplica zero-padding ao mapa de fase\n","    phase_padded, original_size = apply_zero_padding(np.exp(1j * phase_map))\n","\n","    # Cria filtro\n","    filter_mask = create_low_pass_filter(phase_padded.shape, wavelength, dx, NA)\n","\n","    # Propaga para o plano da imagem\n","    reconstructed = angular_spectrum_propagation(phase_padded, wavelength, z, dx, filter_mask)\n","\n","    # Extrai regi√É¬£o central e pega a amplitude (np.abs)\n","    reconstructed = extract_center(np.abs(reconstructed), original_size)\n","\n","    return np.real(reconstructed)  # Garante valor real\n","\n","def reconstruct_image_from_field(complex_field, wavelength, z, dx, NA):\n","    \"\"\"\n","    Reconstr√≥i a imagem a partir de um CAMPO COMPLEXO (Amp + Fase)\n","    \"\"\"\n","    # 1. Aplica zero-padding ao campo complexo\n","    field_padded, original_size = apply_zero_padding(complex_field)\n","\n","    # 2. Cria filtro\n","    filter_mask = create_low_pass_filter(field_padded.shape, wavelength, dx, NA)\n","\n","    # 3. Propaga para o plano da imagem\n","    reconstructed = angular_spectrum_propagation(field_padded, wavelength, z, dx, filter_mask)\n","\n","    # 4. Extrai regi√£o central e pega a amplitude (np.abs)\n","    reconstructed_center = extract_center(reconstructed, original_size)\n","    reconstructed_amplitude = np.abs(reconstructed_center)\n","\n","    return np.real(reconstructed_amplitude) # Garante valor real\n","\n","def gerchberg_saxton_angular_spectrum(target, wavelength, z, dx, NA, num_iter=50):\n","    \"\"\"\n","    Algoritmo de Gerchberg-Saxton com espectro angular\n","    Retornar a imagem original e a reconstru√É¬≠da\n","    \"\"\"\n","    target_padded, original_size = apply_zero_padding(target)\n","    nx_pad, ny_pad = target_padded.shape\n","\n","    filter_mask = create_low_pass_filter((nx_pad, ny_pad), wavelength, dx, NA)\n","\n","    phase = np.random.rand(nx_pad, ny_pad) * 2 * np.pi\n","    U = target_padded * np.exp(1j * phase)\n","\n","    correlations = []\n","\n","    for i in range(num_iter):\n","        # 1. Propaga para o plano da imagem\n","        U_image = angular_spectrum_propagation(U, wavelength, z, dx, filter_mask)\n","\n","        # 2. Mant√É¬©m a fase, atualiza amplitude com alvo\n","        amplitude_image = np.abs(U_image)\n","        phase_image = np.angle(U_image)\n","\n","        # Calcula correla√É¬ß√É¬£o para monitorar converg√É¬™ncia\n","        target_region = extract_center(target_padded, original_size)\n","        recon_region = extract_center(amplitude_image, original_size)\n","\n","        corr = calculate_correlation(target_region, recon_region)\n","        correlations.append(corr)\n","\n","        # Atualiza campo no plano da imagem\n","        U_image_updated = target_padded * np.exp(1j * phase_image)\n","\n","        # 3. Propaga de volta para o plano do holograma\n","        U = angular_spectrum_propagation(U_image_updated, wavelength, -z, dx, filter_mask)\n","\n","        # 4. Mant√É¬©m a fase, atualiza amplitude com incidente (unit√É¬°ria)\n","        phase_hologram = np.angle(U)\n","        U = np.exp(1j * phase_hologram) # Amplitude unit√É¬°ria (holograma de fase)\n","\n","        if (i + 1) % 10 == 0:\n","            print(f\" \tItera√É¬ß√É¬£o GS (X) {i+1}/{num_iter}, Correla√É¬ß√É¬£o: {corr:.4f}\")\n","\n","    phase_final = extract_center(np.angle(U), original_size)\n","\n","    reconstructed_image = reconstruct_image(phase_final, wavelength, z, dx, NA)\n","\n","    return target, reconstructed_image, phase_final, correlations\n","\n","wavelength = 1064e-9  # 1064 nm\n","z = 380e-6           # 380 √é¬ºm\n","dx = 520e-9          # pixel pitch\n","NA = 0.65            # abertura num√É¬©rica\n","num_iter = 200       # n√É¬∫mero de itera√É¬ß√É¬µes\n","\n","print(\"Carregando e pr√É¬©-processando imagem...\")\n","target_original = load_and_preprocess_image('/content/HJV.png', target_size=(90, 90))\n","\n","print(\"Executando algoritmo de Gerchberg-Saxton...\")\n","\n","img_original, img_reconstruida, mapa_de_fase, correlations = gerchberg_saxton_angular_spectrum(\n","    target_original,\n","    wavelength,\n","    z,\n","    dx,\n","    NA,\n","    num_iter\n",")\n","print(f\"\\nCorrela√É¬ß√É¬£o final: {correlations[-1]:.4f}\")\n","\n","print(f\"Dimens√É¬µes da Imagem Original: {img_original.shape}\")\n","print(f\"Dimens√É¬µes da Imagem Reconstru√É¬≠da: {img_reconstruida.shape}\")\n","print(f\"Dimens√É¬µes do Mapa de Fase: {mapa_de_fase.shape}\")\n","\n","# np.savetxt('phase_map_x_polarization.txt', mapa_de_fase)\n","# np.savetxt('correlations.txt', correlations)\n","\n","plt.figure(figsize=(15, 10))\n","\n","plt.subplot(2, 3, 1)\n","plt.imshow(img_original, cmap='gray')\n","plt.title('Imagem Original')\n","\n","plt.subplot(2, 3, 2)\n","plt.imshow(mapa_de_fase, cmap='hsv')\n","plt.title('Mapa de Fase')\n","\n","plt.subplot(2, 3, 3)\n","plt.imshow(img_reconstruida, cmap='gray')\n","plt.title('Imagem Reconstru√É¬≠da')\n","\n","plt.subplot(2, 3, 5)\n","plt.plot(correlations)\n","plt.title('Converg√É¬™ncia')\n","plt.xlabel('Itera√É¬ß√É¬£o')\n","plt.ylabel('Correla√É¬ß√É¬£o')\n","\n","plt.tight_layout()\n","#plt.show()\n","\n","\"\"\"## Polariza√É¬ß√É¬£o y:\"\"\"\n","\n","def generate_dammann_phase_map(\n","    P: float = 520e-9,\n","    wavelength: float = 1064e-9,\n","    supercell_pixels: int = 45,\n","    n_supercells: int = 2,\n","    iters_gs: int = 400,\n","    random_seed: int = 0,\n","    verbose: bool = True\n",") -> tuple[np.ndarray, dict, list]:\n","    \"\"\"\n","    Gera o mapa de fase para uma grade de Dammann (spot-cloud) usando o algoritmo GS.\n","    \"\"\"\n","    np.random.seed(random_seed)\n","\n","    N_super = supercell_pixels\n","    dx = P\n","    d = dx * N_super\n","\n","    # --- Grade k e alvo ---\n","    # (Esta fun√É¬ß√É¬£o usa np.fft, o que n√É¬£o conflita com o Bloco 1)\n","    kx = np.fft.fftfreq(N_super, d=dx)\n","    ky = np.fft.fftfreq(N_super, d=dx)\n","    kx_shift = np.fft.fftshift(kx)\n","    ky_shift = np.fft.fftshift(ky)\n","    KX, KY = np.meshgrid(kx_shift, ky_shift)\n","    K_rad = np.sqrt(KX**2 + KY**2)\n","    target_radius = min(1.0 / wavelength, 1.0 / (2.0 * dx))\n","    target_amp = (K_rad <= target_radius).astype(float)\n","\n","    # --- Algoritmo GS ---\n","    plane_field = np.exp(1j * 2.0 * np.pi * np.random.rand(N_super, N_super))\n","    errors = []\n","\n","    # Loop de itera√É¬ß√É¬£o para Dammann\n","    gs_iterator = range(iters_gs)\n","    if verbose:\n","        # Cria uma barra de progresso se 'verbose' for True\n","        gs_iterator = tqdm(range(iters_gs), desc=\"  Itera√É¬ß√É¬µes GS (Y)\", leave=False)\n","\n","    for it in gs_iterator:\n","        far = np.fft.fft2(plane_field)\n","        far_shift = np.fft.fftshift(far)\n","\n","        amp_current = np.abs(far_shift)\n","        err = np.sqrt(np.mean((amp_current / (amp_current.max() + 1e-9) - target_amp)**2))\n","        errors.append(err)\n","\n","        far_shift = target_amp * np.exp(1j * np.angle(far_shift))\n","        far = np.fft.ifftshift(far_shift)\n","\n","        plane_field = np.fft.ifft2(far)\n","        plane_field = np.exp(1j * np.angle(plane_field))\n","\n","    supercell_phase = np.angle(plane_field)\n","\n","    # --- Constru√É¬ß√É¬£o da Metassuperf√É¬≠cie Completa ---\n","    full_phase = np.tile(supercell_phase, (n_supercells, n_supercells))\n","\n","    if verbose:\n","        print(f\"  Mapa Dammann (Y) gerado: {full_phase.shape} pixels\")\n","\n","    metrics = {} # Vazio, focado apenas na gera√É¬ß√É¬£o de fase\n","\n","    return full_phase, metrics, errors\n","\n","def analyze_and_plot_results(\n","    full_phase: np.ndarray,\n","    errors: list,\n","    P: float,\n","    wavelength: float,\n","    supercell_pixels: int\n",") -> pd.DataFrame:\n","    \"\"\"\n","    Analisa e plota os resultados da metassuperf√É¬≠cie.\n","    Retorna um DataFrame com os dados das ordens propagantes.\n","    \"\"\"\n","\n","    print(\"Iniciando an√É¬°lise e plotagem...\")\n","\n","    # --- Plot 1: Mapa de Fase ---\n","    print(\"Plot 1: Gerando plot_mapa_fase.png...\")\n","    plt.figure(figsize=(7, 6))\n","    plt.imshow(full_phase, cmap='twilight', extent=None)\n","    plt.colorbar(label=\"Fase (rad)\")\n","    plt.title(f\"Mapa de Fase ({full_phase.shape[0]}x{full_phase.shape[1]} pixels)\")\n","    plt.xlabel(\"Pixels (X)\")\n","    plt.ylabel(\"Pixels (Y)\")\n","    plt.tight_layout()\n","    plt.savefig(\"plot_mapa_fase.png\", dpi=150)\n","\n","    # --- Plot 2: Evolu√É¬ß√É¬£o do Erro ---\n","    print(\"Plot 2: Gerando plot_erro_gs.png...\")\n","    plt.figure(figsize=(7, 5))\n","    plt.plot(errors)\n","    plt.xlabel(\"Itera√É¬ß√É¬£o GS\")\n","    plt.ylabel(\"Erro RMSE\")\n","    plt.title(\"Evolu√É¬ß√É¬£o do Erro GS\")\n","    plt.grid(True)\n","    plt.tight_layout()\n","    plt.savefig(\"plot_erro_gs.png\", dpi=150)\n","\n","    # --- An√É¬°lise de Far-Field (C√É¬©lulas 8 & 9) ---\n","    print(\"An√É¬°lise: Calculando Far-Field da metassuperf√É¬≠cie completa...\")\n","    N_full = full_phase.shape[0]\n","    dx_full = P\n","\n","    # Criar a grade k\n","    kx_full = np.fft.fftfreq(N_full, d=dx_full)\n","    ky_full = np.fft.fftfreq(N_full, d=dx_full)\n","    kx_full_shift = np.fft.fftshift(kx_full)\n","    ky_full_shift = np.fft.fftshift(ky_full)\n","\n","    # Calcular o far-field\n","    plane_field_full = np.exp(1j * full_phase)\n","    far_field_full = np.fft.fft2(plane_field_full)\n","    far_field_full_shift = np.fft.fftshift(far_field_full)\n","    far_field_intensity = np.abs(far_field_full_shift)**2\n","\n","    print(\"An√É¬°lise: Extraindo ordens de difra√É¬ß√É¬£o...\")\n","    d_supercell = supercell_pixels * P\n","    max_order = int(np.floor((d_supercell) / wavelength))\n","\n","    p_range = np.arange(-max_order, max_order + 1)\n","    q_range = np.arange(-max_order, max_order + 1)\n","    order_data = []\n","\n","    for p in p_range:\n","        for q in q_range:\n","            k_p = p / d_supercell\n","            k_q = q / d_supercell\n","\n","            idx_p = np.argmin(np.abs(kx_full_shift - k_p))\n","            idx_q = np.argmin(np.abs(ky_full_shift - k_q))\n","\n","            k_rad_order = np.sqrt(k_p**2 + k_q**2)\n","            if k_rad_order <= (1.0 / wavelength):\n","                intensity = far_field_intensity[idx_q, idx_p]\n","                order_data.append({'p': p, 'q': q, 'intensity': intensity, 'k_p': k_p, 'k_q': k_q})\n","\n","    df_orders = pd.DataFrame(order_data)\n","    print(f\"An√É¬°lise conclu√É¬≠da. Encontradas {len(df_orders)} ordens propagantes.\")\n","\n","    print(\"Plot 3: Gerando plot_far_field.png...\")\n","    log_intensity = np.log10(far_field_intensity + 1e-9)\n","    vmax_val = log_intensity.max()\n","    vmin_val = vmax_val - 4\n","\n","    plt.figure(figsize=(7, 6))\n","    plt.imshow(\n","        log_intensity,\n","        cmap='hot',\n","        extent=[kx_full_shift.min(), kx_full_shift.max(), ky_full_shift.min(), ky_full_shift.max()],\n","        vmin=vmin_val,\n","        vmax=vmax_val,\n","        origin='lower'\n","    )\n","\n","    k_max_plot = 1.0 / wavelength\n","    circle = plt.Circle((0, 0), k_max_plot, color='cyan', fill=False, linestyle='--', linewidth=1.5, label=r'$1/\\lambda$')\n","    plt.gca().add_artist(circle)\n","    plt.legend(handles=[circle])\n","\n","    plt.xlim(-k_max_plot * 1.5, k_max_plot * 1.5)\n","    plt.ylim(-k_max_plot * 1.5, k_max_plot * 1.5)\n","    plt.colorbar(label=\"Intensidade (log10)\")\n","    plt.title(\"Far-Field (Intensidade Logar√É¬≠tmica)\")\n","    plt.xlabel(r\"$k_x$ (1/m)\")\n","    plt.ylabel(r\"$k_y$ (1/m)\")\n","    plt.gca().set_aspect('equal')\n","    plt.tight_layout()\n","    plt.savefig(\"plot_far_field.png\", dpi=150)\n","\n","    print(\"Plot 4: Gerando plot_ordens_scatter.png...\")\n","    if not df_orders.empty:\n","        plt.figure(figsize=(7, 6))\n","        norm_intensity = df_orders['intensity'] / (df_orders['intensity'].max() + 1e-9)\n","\n","        sc = plt.scatter(df_orders['p'], df_orders['q'], c=norm_intensity, cmap='viridis', s=50, edgecolor=\"k\", vmin=0)\n","        plt.colorbar(sc, label=\"Intensidade Normalizada\")\n","        plt.xlabel(\"Ordem p\")\n","        plt.ylabel(\"Ordem q\")\n","        plt.title(f\"Mapa das Ordens Propagantes ({len(df_orders)} ordens)\")\n","        plt.grid(True)\n","        plt.gca().set_aspect('equal')\n","        plt.tight_layout()\n","        plt.savefig(\"plot_ordens_scatter.png\", dpi=150)\n","    else:\n","        print(\"Plot 4: DataFrame de ordens vazio, pulando o scatter plot.\")\n","\n","    print(\"\\nTodos os plots foram salvos como arquivos .png.\")\n","\n","    return df_orders\n","\n","P = 520e-9\n","wavelength = 1064e-9\n","supercell_pixels = 45\n","n_supercells = 2\n","iters_gs = 400\n","random_seed = 0\n","\n","print(\"Iniciando Gera√É¬ß√É¬£o de Fase...\")\n","full_phase, _, errors = generate_dammann_phase_map(\n","    P=P,\n","    wavelength=wavelength,\n","    supercell_pixels=supercell_pixels,\n","    n_supercells=n_supercells,\n","    iters_gs=iters_gs,\n","    random_seed=random_seed,\n","    verbose=True\n",")\n","print(\"Gera√É¬ß√É¬£o de Fase Conclu√É¬≠da.\")\n","\n","df_ordens_propagantes = analyze_and_plot_results(\n","    full_phase=full_phase,\n","    errors=errors,\n","    P=P,\n","    wavelength=wavelength,\n","    supercell_pixels=supercell_pixels\n",")\n","\n","print(\"\\n--- Resumo das Ordens ---\")\n","print(df_ordens_propagantes.head())\n","\n","\"\"\"# Carregamento dos Modelos Treinados\"\"\"\n","\n","IMG_SIZE = 64\n","LATENT_DIM = 128 # Dimens√É¬£o do vetor latente\n","\n","GENERATOR_PATH = \"/content/generator_teste_5_final.pth\"\n","SIMULATOR_PATH = \"/content/simulador_NG_teste_1.pth\"\n","\n","# --- Componentes Globais ---\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Carregar Gerador\n","try:\n","    generator = CPPN_Generator(latent_dim=LATENT_DIM, in_coords=2).to(device)\n","    generator.load_state_dict(torch.load(GENERATOR_PATH, map_location=device))\n","    generator.eval()\n","    print(f\"Gerador '{GENERATOR_PATH}' carregado em {device}.\")\n","except Exception as e:\n","    print(f\"Erro ao carregar Gerador: {e}\")\n","    exit()\n","\n","# Carregar Simulador\n","try:\n","    # Use a arquitetura ResNet que voc√É¬™ definiu (ex: ResNet-18)\n","    simulator = ResNetSimulator(in_channels=1, n_outputs=4).to(device)\n","    simulator.load_state_dict(torch.load(SIMULATOR_PATH, map_location=device))\n","    simulator.eval()\n","    print(f\"Simulador '{SIMULATOR_PATH}' carregado em {device}.\")\n","except Exception as e:\n","    print(f\"Erro ao carregar Simulador: {e}\")\n","    exit()\n","\n","# Criar a grade de coordenadas (apenas uma vez)\n","def make_coordinate_grid(size, dev):\n","    xs = np.linspace(-1, 1, size)\n","    ys = np.linspace(-1, 1, size)\n","    xx, yy = np.meshgrid(xs, ys)\n","    coords = np.stack([xx.ravel(), yy.ravel()], axis=-1).astype(np.float32)\n","    return torch.from_numpy(coords).to(dev)\n","\n","coords_grid = make_coordinate_grid(IMG_SIZE, device)\n","print(\"Grade de coordenadas criada.\")\n","\n","\"\"\"\n","============================================================================\n","## Otimiza√ß√£o por Gradiente (Substitui√ß√£o do GA)\n","============================================================================\n","\"\"\"\n","\n","# ---------------------------------------------------------------------------\n","# Configura√ß√µes da Otimiza√ß√£o por Gradiente\n","# ---------------------------------------------------------------------------\n","N_STEPS = 500       # N√∫mero de passos de otimiza√ß√£o (similar ao NGEN)\n","LR = 0.01           # Taxa de aprendizado para o Adam\n","BATCH_PIXELS = 1024 # N√∫mero de pixels processados em paralelo na GPU\n","PRINT_EVERY = 20    # Imprimir o progresso a cada N passos\n","\n","# Caminhos de salvamento (mesmos do script original)\n","save_dir = \"resultados_otimizacao_gradiente\" # Novo diret√≥rio para n√£o misturar\n","os.makedirs(save_dir, exist_ok=True)\n","latent_vectors_path = os.path.join(save_dir, \"latent_vectors_optimized.npy\")\n","\n","# ---------------------------------------------------------------\n","# 1. Mapas de fase alvo e Tensores\n","# ---------------------------------------------------------------\n","phase_map_x = mapa_de_fase  # da se√ß√£o GS\n","phase_map_y = full_phase    # da se√ß√£o Dammann\n","rows, cols = phase_map_x.shape\n","latent_dim = LATENT_DIM_GA # Usando a dimens√£o do seu GA\n","\n","print(f\"\\n‚öôÔ∏è Iniciando otimiza√ß√£o por Gradiente em {rows}x{cols} pixels ({rows*cols} totais)...\\n\")\n","\n","# Mover modelos para o device (j√° deve estar feito, mas garantindo)\n","generator.to(device)\n","simulator.to(device)\n","generator.eval()\n","simulator.eval()\n","\n","# Criar tensores de alvo na GPU\n","targets_phase_x = torch.tensor(phase_map_x, dtype=torch.float32, device=device)\n","targets_phase_y = torch.tensor(phase_map_y, dtype=torch.float32, device=device)\n","\n","# Criar a grade de coordenadas (j√° existe como 'coords_grid')\n","coords_grid_tensor = coords_grid.to(device)\n","\n","# ---------------------------------------------------------------\n","# 2. Inicializar Vetores Latentes (Otimiz√°veis)\n","# ---------------------------------------------------------------\n","# Criamos UM tensor para TODOS os vetores latentes\n","# E informamos ao PyTorch que queremos calcular gradientes para ele\n","latent_vectors_tensor = torch.randn(\n","    (rows, cols, latent_dim),\n","    dtype=torch.float32,\n","    device=device,\n","    requires_grad=True\n",")\n","\n","# ---------------------------------------------------------------\n","# 3. Fun√ß√µes de Custo (Loss) e Otimizador\n","# ---------------------------------------------------------------\n","optimizer = torch.optim.Adam([latent_vectors_tensor], lr=LR)\n","pi_tensor = torch.tensor(2 * np.pi, device=device)\n","\n","def calculate_batch_phase_loss(sim_outputs, target_phase_x_batch, target_phase_y_batch):\n","    \"\"\"\n","    Calcula o erro de fase L1 (com wrapping) para um lote de pixels.\n","    \"\"\"\n","    s_tm_real = sim_outputs[:, 0]\n","    s_tm_imag = sim_outputs[:, 1]\n","    s_te_real = sim_outputs[:, 2]\n","    s_te_imag = sim_outputs[:, 3]\n","\n","    sim_phase_x = torch.atan2(s_te_imag, s_te_real)\n","    sim_phase_y = torch.atan2(s_tm_imag, s_tm_real)\n","\n","    # Targets j√° s√£o tensores (batch_size,)\n","    error_x = torch.abs(sim_phase_x - target_phase_x_batch)\n","    error_y = torch.abs(sim_phase_y - target_phase_y_batch)\n","\n","    # Corrigir o phase wrapping\n","    error_x = torch.min(error_x, pi_tensor - error_x)\n","    error_y = torch.min(error_y, pi_tensor - error_y)\n","\n","    # Retorna o erro L1 total somado (error_x + error_y)\n","    # e calculamos a M√âDIA sobre o lote\n","    return (error_x + error_y).mean()\n","\n","def get_per_pixel_errors(z_tensor, target_x_tensor, target_y_tensor):\n","    \"\"\"\n","    Fun√ß√£o helper para calcular o erro final por pixel.\n","    Usado para popular as m√©tricas (all_initial_avg_fitness e all_best_fitness).\n","    \"\"\"\n","    print(\" ¬† ¬†Calculando erros por pixel (para m√©tricas)...\")\n","    z_flat = z_tensor.view(-1, latent_dim)\n","    target_x_flat = target_x_tensor.view(-1)\n","    target_y_flat = target_y_tensor.view(-1)\n","\n","    all_errors = []\n","    with torch.no_grad():\n","        for i in range(0, z_flat.shape[0], BATCH_PIXELS):\n","            z_batch = z_flat[i:i + BATCH_PIXELS]\n","            target_x_batch = target_x_flat[i:i + BATCH_PIXELS]\n","            target_y_batch = target_y_flat[i:i + BATCH_PIXELS]\n","\n","            imgs = generator(coords_grid_tensor, z_batch)\n","            outputs = simulator(imgs)\n","\n","            # Reutiliza a l√≥gica da loss, mas sem a m√©dia\n","            s_tm_real = outputs[:, 0]\n","            s_tm_imag = outputs[:, 1]\n","            s_te_real = outputs[:, 2]\n","            s_te_imag = outputs[:, 3]\n","            sim_phase_x = torch.atan2(s_te_imag, s_te_real)\n","            sim_phase_y = torch.atan2(s_tm_imag, s_tm_real)\n","            error_x = torch.abs(sim_phase_x - target_x_batch)\n","            error_y = torch.abs(sim_phase_y - target_y_batch)\n","            error_x = torch.min(error_x, pi_tensor - error_x)\n","            error_y = torch.min(error_y, pi_tensor - error_y)\n","\n","            batch_errors = (error_x + error_y).cpu().numpy()\n","            all_errors.extend(batch_errors)\n","\n","    return all_errors\n","\n","# ---------------------------------------------------------------\n","# 4. Loop de Otimiza√ß√£o Principal\n","# ---------------------------------------------------------------\n","\n","# --- M√©tricas (para compatibilidade com seu script) ---\n","# 1. Erro inicial (equivalente √† \"Gera√ß√£o 0\" do GA)\n","all_initial_avg_fitness = get_per_pixel_errors(latent_vectors_tensor, targets_phase_x, targets_phase_y)\n","\n","print(\"\\nIniciando loop de otimiza√ß√£o por gradiente...\")\n","start_time = time.time()\n","\n","# √çndices de todos os pixels (ex: 0 a 8099)\n","total_pixels = rows * cols\n","pixel_indices = torch.arange(total_pixels, device=device)\n","\n","# Achata os tensores para facilitar o batching\n","z_flat = latent_vectors_tensor.view(-1, latent_dim)\n","target_x_flat = targets_phase_x.view(-1)\n","target_y_flat = targets_phase_y.view(-1)\n","\n","\n","for step in range(N_STEPS):\n","    # Embaralha os pixels a cada √©poca\n","    permuted_indices = pixel_indices[torch.randperm(total_pixels)]\n","\n","    total_loss_epoch = 0\n","    num_batches = 0\n","\n","    for batch_start in range(0, total_pixels, BATCH_PIXELS):\n","        batch_indices = permuted_indices[batch_start : batch_start + BATCH_PIXELS]\n","\n","        # Pega os dados do lote\n","        # IMPORTANTE: Pegamos os vetores latentes do tensor *achatado*\n","        z_batch = z_flat[batch_indices]\n","        target_x_batch = target_x_flat[batch_indices]\n","        target_y_batch = target_y_flat[batch_indices]\n","\n","        # --- Etapa de Otimiza√ß√£o ---\n","        optimizer.zero_grad()\n","\n","        # 1. Forward pass\n","        imgs_batch = generator(coords_grid_tensor, z_batch)\n","        outputs_raw = simulator(imgs_batch)\n","\n","        # 2. Calcular Loss\n","        loss = calculate_batch_phase_loss(outputs_raw, target_x_batch, target_y_batch)\n","\n","        # 3. Backward pass\n","        loss.backward()\n","\n","        # 4. Atualizar pesos (vetores latentes)\n","        optimizer.step()\n","\n","        total_loss_epoch += loss.item()\n","        num_batches += 1\n","\n","    # Imprimir progresso\n","    avg_loss = total_loss_epoch / num_batches\n","    if (step + 1) % PRINT_EVERY == 0 or step == 0:\n","        print(f\" ¬†Passo [{step+1}/{N_STEPS}], Loss M√©dia: {avg_loss:.6f}\")\n","\n","# ---------------------------------------------------------------\n","# 5. Resultado final\n","# ---------------------------------------------------------------\n","total_execution_time = time.time() - start_time\n","print(f\"\\nüéâ Otimiza√ß√£o por Gradiente conclu√≠da!\")\n","print(f\"Tempo total: {total_execution_time:.2f} s\")\n","\n","# --- M√©tricas (para compatibilidade) ---\n","# 2. Erro final (equivalente ao \"Best Fitness\" do GA)\n","print(\"Calculando m√©tricas finais...\")\n","all_best_fitness = get_per_pixel_errors(latent_vectors_tensor, targets_phase_x, targets_phase_y)\n","\n","# 3. NFE (N√∫mero de Avalia√ß√µes de Fun√ß√£o)\n","# Cada passo otimiza todos os pixels, ent√£o NFE total = N_STEPS * total_pixels\n","total_nfe = N_STEPS * total_pixels\n","\n","# 4. Salvar os vetores latentes otimizados (como o script GA fazia)\n","latent_vectors = latent_vectors_tensor.detach().cpu().numpy()\n","np.save(latent_vectors_path, latent_vectors)\n","print(f\"Resultados salvos em:\\n{latent_vectors_path}\\n\")\n","\n","\n","\"\"\"\n","============================================================================\n","## C√°lculo e Salvamento de M√©tricas (Gradiente)\n","============================================================================\n","\"\"\"\n","\n","print(\"\\nCalculando m√©tricas finais da otimiza√ß√£o (Gradiente)...\")\n","\n","num_pixels = rows * cols\n","# Esta vari√°vel 'all_best_fitness' foi criada com sucesso pelo bloco de gradiente\n","fitness_array = np.array(all_best_fitness)\n","\n","# 1. Salvar os dados do erro para compara√ß√£o posterior\n","np.save('gradient_errors.npy', fitness_array)\n","\n","# 2. Gerar o histograma apenas do Gradiente\n","print(\"Gerando histograma de erros do Gradiente...\")\n","plt.figure(figsize=(10, 6))\n","plt.hist(fitness_array, bins=50, alpha=0.7, color='green') # Cor verde para Gradiente\n","plt.title(f'Histograma de Erro (Fitness) - M√©todo Gradiente (N={len(fitness_array)} pixels)')\n","plt.xlabel('Erro Total por Pixel (Fitness Final)')\n","plt.ylabel('Contagem de Pixels')\n","plt.grid(True, linestyle='--', alpha=0.5)\n","plt.savefig('histograma_Gradiente.png', dpi=150)\n","plt.show()\n","\n","# ----------------------------\n","# 3. Calcular estat√≠sticas\n","# ----------------------------\n","\n","# A fitness J√Å √© o erro, ent√£o a m√©dia √© o Erro M√©dio.\n","mean_error = np.mean(fitness_array)\n","min_best_fitness = np.min(fitness_array) # O melhor pixel individual\n","\n","# Desvio Padr√£o\n","std_dev_fitness = np.std(fitness_array)\n","\n","# Taxa de Sucesso\n","SUCCESS_THRESHOLD = 0.1 # <-- Voc√™ pode ajustar este valor\n","successful_pixels = np.sum(fitness_array < SUCCESS_THRESHOLD)\n","success_rate = (successful_pixels / num_pixels) * 100\n","\n","# Converg√™ncia\n","# 'all_initial_avg_fitness' tamb√©m foi criada pelo bloco de gradiente\n","avg_initial_fitness = np.mean(all_initial_avg_fitness)\n","avg_final_fitness = mean_error\n","convergence_improvement = (avg_initial_fitness - avg_final_fitness)\n","\n","# total_execution_time e total_nfe j√° existem do bloco de gradiente\n","\n","# --- Criar o arquivo .txt ---\n","# *** NOME DE ARQUIVO ATUALIZADO ***\n","metrics_filename = \"optimization_metrics_GRADIENTE.txt\"\n","try:\n","    with open(metrics_filename, \"w\", encoding=\"utf-8\") as f:\n","        # *** CONTE√öDO ATUALIZADO ***\n","        f.write(\"--- M√©tricas da Otimiza√ß√£o por GRADIENTE da Metassuperf√≠cie ---\\n\\n\")\n","        f.write(f\"Par√¢metros do Otimizador (Adam):\\n\")\n","        f.write(f\"  N√∫mero de Passos (Steps): {N_STEPS}\\n\")\n","        f.write(f\"  Taxa de Aprendizado (LR): {LR}\\n\")\n","        f.write(f\"  Tamanho do Lote (Batch Size): {BATCH_PIXELS}\\n\")\n","        f.write(f\"  Total de Meta-√Åtomos Otimizados: {num_pixels} ({rows}x{cols})\\n\\n\")\n","\n","        f.write(\"--- Performance Computacional ---\\n\")\n","        f.write(f\"Tempo de Execu√ß√£o Total: {total_execution_time:.2f} segundos\\n\")\n","        f.write(f\"N√∫mero Total de Avalia√ß√µes (NFE): {total_nfe}\\n\")\n","        f.write(f\"NFE por pixel (m√©dia): {total_nfe / num_pixels:.1f}\\n\\n\")\n","\n","        f.write(\"--- Qualidade da Otimiza√ß√£o (Fitness/Erro) ---\\n\")\n","        f.write(f\"Erro M√©dio Final (M√©dia do Best Fitness): {mean_error:.6f}\\n\")\n","        f.write(f\"Melhor Fitness Individual (pixel √∫nico): {min_best_fitness:.6f}\\n\")\n","        f.write(f\"Desvio Padr√£o (Fitness): {std_dev_fitness:.6f}\\n\\n\")\n","\n","        f.write(\"--- M√©tricas de Converg√™ncia ---\\n\")\n","        f.write(f\"Erro M√©dio Inicial (M√©dia da Pop. Step 0): {avg_initial_fitness:.6f}\\n\")\n","        f.write(f\"Melhoria M√©dia (Inicial - Final): {convergence_improvement:.6f}\\n\")\n","        f.write(f\"Taxa de Sucesso (Erro < {SUCCESS_THRESHOLD}): {success_rate:.2f} %\\n\")\n","\n","    print(f\"M√©tricas salvas com sucesso em '{metrics_filename}'\")\n","\n","except Exception as e:\n","    print(f\"Erro ao salvar arquivo de m√©tricas: {e}\")\n","\"\"\"# Verifica√É¬ß√É¬£o de Performance\"\"\"\n","\n","\"\"\"\n","============================================================================\n","## Verifica√ß√£o de Performance (Gradiente)\n","============================================================================\n","\"\"\"\n","\n","print(\"\\nVerificando performance final (em lotes) da metassuperf√≠cie otimizada...\")\n","\n","# Inicializa os arrays\n","final_phase_x = np.zeros((rows, cols))\n","final_phase_y = np.zeros((rows, cols))\n","final_amp_x = np.zeros((rows, cols))\n","final_amp_y = np.zeros((rows, cols))\n","\n","# Usa a grade de coordenadas global\n","coords_grid_tensor = coords_grid\n","\n","with torch.no_grad():\n","    for i in tqdm(range(rows), desc=\"Verificando linhas\"):\n","\n","        # 1. Pega todos os vetores latentes da linha\n","        # A vari√°vel 'latent_vectors' foi salva corretamente pelo bloco de gradiente\n","        z_row_list = [latent_vectors[i, j] for j in range(cols)]\n","        z_row_tensor = torch.from_numpy(np.array(z_row_list)).float().to(device)\n","        # Shape: (cols, latent_dim)\n","\n","        # 2. Gera e simula TODAS as imagens da linha de uma vez (em batch)\n","        imgs_batch = generator(coords_grid_tensor, z_row_tensor)\n","        imgs_binary_batch = (imgs_batch > 0.5).float() # Binariza\n","\n","        # outputs_raw ter√° shape (cols, 4)\n","        outputs_raw = simulator(imgs_binary_batch)\n","\n","        # 3. Processa os resultados do batch\n","        s_tm_real = outputs_raw[:, 0]\n","        s_tm_imag = outputs_raw[:, 1]\n","        s_te_real = outputs_raw[:, 2]\n","        s_te_imag = outputs_raw[:, 3]\n","\n","        # Calcula fases e amplitudes com opera√ß√µes de tensor\n","        s_te_complex = torch.complex(s_te_real, s_te_imag)\n","        s_tm_complex = torch.complex(s_tm_real, s_tm_imag)\n","\n","        # 4. Salva no array (movendo para CPU de uma vez)\n","        final_phase_x[i, :] = torch.angle(s_te_complex).cpu().numpy()\n","        final_amp_x[i, :] = torch.abs(s_te_complex).cpu().numpy()\n","        final_phase_y[i, :] = torch.angle(s_tm_complex).cpu().numpy()\n","        final_amp_y[i, :] = torch.abs(s_tm_complex).cpu().numpy()\n","\n","print(\"Verifica√ß√£o em lote conclu√≠da.\")\n","\n","# --- Plotar resultados ---\n","fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n","# *** T√çTULO ATUALIZADO ***\n","plt.suptitle(\"Resultados Finais da Otimiza√ß√£o (GRADIENTE)\", fontsize=16)\n","\n","# Coluna 1: Alvos\n","im0 = axes[0, 0].imshow(phase_map_x, cmap='hsv', vmin=-np.pi, vmax=np.pi)\n","axes[0, 0].set_title(\"Alvo - Fase X (rad)\")\n","fig.colorbar(im0, ax=axes[0, 0])\n","\n","im1 = axes[1, 0].imshow(phase_map_y, cmap='hsv', vmin=-np.pi, vmax=np.pi)\n","axes[1, 0].set_title(\"Alvo - Fase Y (rad)\")\n","fig.colorbar(im1, ax=axes[1, 0])\n","\n","# Coluna 2: Fases Obtidas\n","im2 = axes[0, 1].imshow(final_phase_x, cmap='hsv', vmin=-np.pi, vmax=np.pi)\n","axes[0, 1].set_title(\"Obtido - Fase X (rad)\")\n","fig.colorbar(im2, ax=axes[0, 1])\n","\n","im3 = axes[1, 1].imshow(final_phase_y, cmap='hsv', vmin=-np.pi, vmax=np.pi)\n","axes[1, 1].set_title(\"Obtido - Fase Y (rad)\")\n","fig.colorbar(im3, ax=axes[1, 1])\n","\n","# Coluna 3: Amplitudes Obtidas\n","im4 = axes[0, 2].imshow(final_amp_x, cmap='viridis', vmin=0, vmax=1)\n","axes[0, 2].set_title(\"Obtido - Amplitude X (Efici√™ncia)\")\n","fig.colorbar(im4, ax=axes[0, 2])\n","\n","im5 = axes[1, 2].imshow(final_amp_y, cmap='viridis', vmin=0, vmax=1)\n","axes[1, 2].set_title(\"Obtido - Amplitude Y (Efici√™ncia)\")\n","fig.colorbar(im5, ax=axes[1, 2])\n","\n","plt.tight_layout()\n","\n","# *** NOME DE ARQUIVO ATUALIZADO ***\n","plt.savefig(\"Resultados_Otimizacao_GRADIENTE.png\", dpi=300, bbox_inches=\"tight\")\n","plt.show()\n","#plt.show()\n","\n","\"\"\"\n","============================================================================\n","## Gerando Imagem da Metassuperf√≠cie Completa (Gradiente)\n","============================================================================\n","\"\"\"\n","\n","print(\"\\n--- Gerando Imagem da Metassuperf√≠cie Completa ---\")\n","print(\"Isso pode demorar alguns minutos e consumir bastante RAM...\")\n","\n","try:\n","    # 'latent_vectors' foi carregado/definido pelo bloco de gradiente\n","    rows, cols = latent_vectors.shape[0], latent_vectors.shape[1]\n","    img_size = IMG_SIZE\n","\n","    full_surface_rows_list = []\n","\n","    for i in tqdm(range(rows), desc=\"Gerando Linhas da Metassuperf√≠cie\"):\n","\n","        # 1. Pegar todos os vetores latentes desta linha\n","        z_row_list = [latent_vectors[i, j] for j in range(cols)]\n","        z_row_tensor = torch.from_numpy(np.array(z_row_list)).float().to(device)\n","\n","        # 2. Gerar TODAS as imagens da linha de uma vez (em batch)\n","        with torch.no_grad():\n","            img_row_batch = generator(coords_grid, z_row_tensor)\n","            img_row_binary = (img_row_batch > 0.5).float()\n","\n","        # 3. \"Costurar\" as imagens horizontalmente\n","        img_row_binary = img_row_binary.squeeze(1)\n","        img_row_binary = img_row_binary.transpose(0, 1)\n","        final_row_img = img_row_binary.reshape(img_size, -1)\n","\n","        # 4. Mover para CPU (para liberar VRAM) e adicionar √† lista\n","        full_surface_rows_list.append(final_row_img.cpu().numpy())\n","\n","    # 5. \"Costurar\" todas as linhas verticalmente\n","    print(\"Costurando imagem final...\")\n","    final_metasurface_image = np.concatenate(full_surface_rows_list, axis=0)\n","\n","    print(f\"Imagem final gerada com dimens√µes: {final_metasurface_image.shape}\")\n","\n","    # 6. Salvar\n","    # *** NOME DE ARQUIVO ATUALIZADO ***\n","    output_filename = \"metasurface_completa_geometria_GRADIENTE.png\"\n","    plt.imsave(output_filename, final_metasurface_image, cmap='gray')\n","    print(f\"Imagem da metassuperf√≠cie completa salva em: {output_filename}\")\n","\n","except Exception as e:\n","    print(f\"Ocorreu um erro ao gerar a metassuperf√≠cie completa: {e}\")\n","\n","\"\"\"\n","============================================================================\n","## Reconstru√ß√£o Final da Imagem (Gradiente)\n","============================================================================\n","\"\"\"\n","\n","print(\"\\nReconstruindo imagem final a partir do campo otimizado pelo GRADIENTE...\")\n","\n","# Criar o campo complexo para Pol-X (Holograma)\n","# Usamos 'final_amp_x' e 'final_phase_x' da \"Verifica√ß√£o de Performance\"\n","campo_complexo_x_final_grad = final_amp_x * np.exp(1j * final_phase_x)\n","\n","# Usar os mesmos par√¢metros do GS (wavelength, z, dx, NA)\n","img_reconstruida_final_grad = reconstruct_image_from_field(\n","    campo_complexo_x_final_grad,\n","    wavelength,\n","    z,\n","    dx,\n","    NA\n",")\n","print(\"Reconstru√ß√£o final (Gradiente) conclu√≠da.\")\n","\n","\n","print(\"Gerando gr√°fico de compara√ß√£o de reconstru√ß√£o (Gradiente)...\")\n","\n","fig_grad_recon = plt.figure(figsize=(18, 6))\n","# *** T√çTULO ATUALIZADO ***\n","plt.suptitle(\"Compara√ß√£o da Imagem Reconstru√≠da (Pol-X)\", fontsize=16)\n","\n","# Painel 1: Imagem Alvo Original\n","plt.subplot(1, 3, 1)\n","plt.imshow(img_original, cmap='gray')\n","plt.title(\"1. Imagem Alvo Original\")\n","plt.xlabel(\"Pixel X\")\n","plt.ylabel(\"Pixel Y\")\n","\n","# Painel 2: Reconstru√ß√£o Ideal (do GS, Fase Pura)\n","# Esta √© a 'img_reconstruida' da se√ß√£o GS\n","plt.subplot(1, 3, 2)\n","plt.imshow(img_reconstruida, cmap='gray')\n","plt.title(\"2. Reconstru√ß√£o Ideal (GS - Fase Pura)\")\n","plt.xlabel(\"Pixel X\")\n","plt.ylabel(\"Pixel Y\")\n","\n","# Painel 3: Reconstru√ß√£o Real (do Gradiente + Simulador)\n","plt.subplot(1, 3, 3)\n","plt.imshow(img_reconstruida_final_grad, cmap='gray')\n","# *** T√çTULO ATUALIZADO ***\n","plt.title(\"3. Reconstru√ß√£o Real (Gradiente + Simulador)\")\n","plt.xlabel(\"Pixel X\")\n","plt.ylabel(\"Pixel Y\")\n","\n","plt.tight_layout()\n","# *** NOME DE ARQUIVO ATUALIZADO ***\n","plt.savefig(\"comparacao_reconstrucao_GRADIENTE.png\", dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","print(\"Gr√°fico 'comparacao_reconstrucao_GRADIENTE.png' salvo.\")"]}]}